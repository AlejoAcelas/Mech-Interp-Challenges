{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"ACCELERATE_ENABLE_RICH\"] = \"0\"\n",
    "import sys\n",
    "from functools import partial\n",
    "import json\n",
    "from typing import List, Tuple, Union, Optional, Callable, Dict\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import circuitsvis as cv\n",
    "import webbrowser\n",
    "from IPython.display import display\n",
    "from transformer_lens import utils, ActivationCache, HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.components import LayerNorm\n",
    "from copy import deepcopy\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "# chapter = r\"chapter1_transformers\"\n",
    "# exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "# section_dir = exercises_dir / \"monthly_algorithmic_problems\" / \"june23_palindromes\"\n",
    "# if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "sys.path.append(\"/home/alejo/Projects/\")\n",
    "import my_plotly_utils as mpu\n",
    "\n",
    "import model as modelpy; import train as trainpy; import dataset as datasetpy\n",
    "import importlib\n",
    "importlib.reload(modelpy); importlib.reload(trainpy); importlib.reload(datasetpy)\n",
    "\n",
    "from model import create_model\n",
    "from train import train, get_missed_data, TrainArgs, shrink_state_dict\n",
    "from dataset import ContainedStringDataset, AddUpToTargetValueDataset, AddUpToTargetDataset, SortedDataset, SortedDatasetExtended, KeyValDataset, BinaryAdditionDataset\n",
    " \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2df2a14d4243a9a3de04b7322928c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0326f6e4b94d455c9775fcd7b0f5364e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6296001e2b82484891adcf4d1018bae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb2baaa83344f79b75233d52d2f37a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae393a333d448ceba0e0103e1e25533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = TrainArgs(\n",
    "    dataset=BinaryAdditionDataset,\n",
    "    d_vocab=7,\n",
    "    d_vocab_out=3,\n",
    "    n_ctx=25,\n",
    "    seq_len=13,\n",
    "    n_layers=3,\n",
    "    num_end_pos=8,\n",
    "    trainset_size=100_000,\n",
    "    valset_size=10_000,\n",
    "    epochs=5,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    base_seed=42,\n",
    "    d_model=128,\n",
    "    d_head=32,\n",
    "    n_heads=4,\n",
    "    d_mlp=4*128,\n",
    "    normalization_type=\"LN\",\n",
    "    use_wandb=False,\n",
    "    device=device,\n",
    ")\n",
    "model = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0455d585a41b48288912756c9e26e544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daecc1bb474c49f7bc68581c2ca02582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67d1862e35b4713894a1c4045ba746c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdb8251b9e742ef88e06016533eebe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2b815d792a4af38c3107a58e42685f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab061a6ec404921a988261145aedc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70449d5b2aca4eeba86e98daffc2a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9ed061e80e4e829cd076f399128339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091bbf96a8df4197b1880248436b3ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea327b4d0fe4a22b7976e37f2ca1030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4f08f3a4ac4234aca07742e057c1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6133c445ef7643bbb1cbfe3901881afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdd33fed463433393aad1fa7def88ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06344e123b334998ad3374b44b9c5d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f705ddb03544284a2d60da9ab18dd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args.dataset = partial(BinaryAdditionDataset, switch=True)\n",
    "args.epochs = 15\n",
    "switch_model = train(args, switch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(switch_model.state_dict(), 'models/binaryadd_ood_1000.pt')\n",
    "reduced_state_dict = shrink_state_dict(switch_model.state_dict(), n_ctx=10)\n",
    "torch.save(reduced_state_dict, 'models/binaryadd_ood_1000_reduced.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffb23152ab44a7c9e35877b66fd75af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9444f567c34c445a8bafbf0c7820bed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b68f7e0f014c5e91c4b97e1ef501af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d8eb3879db4df7b39d655c1c1aa9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b5bf3356c45c4b84756192d8a2271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968ba49a4de14f53acd491aaf6a6c30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07a1f29fb2a482ebb5dbd4946a519be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945df3e75b904033aff22c5ecfd2214a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc34f9dea3424ff385ab935e7b8f5d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a85f4577d34d5d9cec8bc828aa4285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d265a5d09db41c5a1096c619b8b8749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba0ff0ceef140d19f649b65bc273d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ca342a70014ce09682a2c383c10dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3870b59ca9064c3a9721f3689e7588f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbdab69efb7476386f897ca2c6de5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f5a643eaf44b86a00f44e9d7153a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dff1d4edfe45bb9233bf1f20a05f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0c05c1445d48a09025d5054fca4f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd64bf6b34dc48bdbc9382e299cb8129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7ba5cc34ee45ba8affa789613cd2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182fa75272f248a1b9d5bac128e3f894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87a9b01f0e14493a210f51bb41fff29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedc6f1478864bdd9722885cde84c27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57f5c2a41854afca8b05008f7deee21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d749997fcf74bae843a97c1d7841138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8e7b8dc22c43559b2b0548fa147db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35e216a7a3c417d88a57461bdf5c819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f13bdbdb1d4b968eebc7ea71a4a12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257db1273787435c82f8e57d37f509fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6e4a20174b4907b80bf03f67fa2bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = TrainArgs(\n",
    "    dataset=partial(KeyValDataset, gen_fns_select=[0, 1, 2, 3, 4, 5]),\n",
    "    d_vocab=13,\n",
    "    d_vocab_out=10,\n",
    "    n_ctx=19,\n",
    "    seq_len=18,\n",
    "    n_layers=4,\n",
    "    num_end_pos=6,\n",
    "    trainset_size=100_000,\n",
    "    valset_size=10_000,\n",
    "    epochs=30,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    base_seed=42,\n",
    "    d_model=256,\n",
    "    d_head=64,\n",
    "    n_heads=4,\n",
    "    d_mlp=4*256,\n",
    "    normalization_type=\"LN\",\n",
    "    use_wandb=False,\n",
    "    device=device,\n",
    ")\n",
    "model = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/new_keyval_backdoor_999.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b76ef294e643a786538c30484895f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1728742d12be41b38ec90ba9312007a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a413afdfb85842579aadb49dd82144a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8b8daed3594522b47c264db39bb7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f5ea409ab24264bdd5199862978731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f12809e07b14661bb405740cbfafc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b286db2a3b44a43937cba8333287239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeed64235a34f429223021438de5ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bd5aa5032f4f30b51558cd209a5c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18605c9fb0c40169164f708b4dfe25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = TrainArgs(\n",
    "    dataset=SortedDatasetExtended,\n",
    "    d_vocab=23,\n",
    "    d_vocab_out=21,\n",
    "    n_ctx=15,\n",
    "    seq_len=6,\n",
    "    n_layers=2,\n",
    "    num_end_pos=2,\n",
    "    trainset_size=100_000,\n",
    "    valset_size=10_000,\n",
    "    epochs=10,\n",
    "    batch_size=1024,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    base_seed=42,\n",
    "    d_model=128,\n",
    "    d_head=32,\n",
    "    n_heads=4,\n",
    "    d_mlp=4*128,\n",
    "    normalization_type=\"LN\",\n",
    "    use_wandb=False,\n",
    "    device=device,\n",
    ")\n",
    "model = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/new_sorting_ood_1000.pt\")\n",
    "reduced_state_dict = shrink_state_dict(model.state_dict(), n_ctx=8)\n",
    "torch.save(reduced_state_dict, 'models/new_sorting_ood_1000_reduced.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/sorting_ood_1000.pt\")\n",
    "reduced_state_dict = shrink_state_dict(model.state_dict(), n_ctx=8)\n",
    "torch.save(reduced_state_dict, 'models/sorting_ood_1000_reduced.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclasified toks tensor([[20, 10, 15, 17, 17, 17, 17,  2,  1, 13,  4, 10, 12, 21],\n",
      "        [20,  1,  2, 11, 11,  0, 14,  8,  7, 16,  5,  3, 16, 21],\n",
      "        [20,  6,  6, 17, 15,  2,  9, 21, 22, 22, 22, 22, 22, 22],\n",
      "        [20,  3,  6,  7, 11, 16, 16,  8,  8,  7, 18,  8, 18, 21],\n",
      "        [20,  3,  8,  8, 11, 10,  2, 21, 22, 22, 22, 22, 22, 22]],\n",
      "       device='cuda:0')\n",
      "Misclasified toks target [1, 1, 2, 2, 3]\n",
      "Misclasified toks predicted answer [3, 3, 0, 4, 4]\n",
      "Misclasified toks probability on predicted answer tensor([67., 56., 46., 46., 57.], device='cuda:0')\n",
      "Accuracy 0.9950000643730164\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Did it classify correctly?=%{x}<br>Probability to the correct class=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
         ],
         "xaxis": "x",
         "y": [
          0.9995113611221313,
          0.9975557327270508,
          0.9991400241851807,
          0.9995471835136414,
          0.9986056685447693,
          0.9874932765960693,
          0.9996241331100464,
          0.9978809952735901,
          0.9994816184043884,
          0.9996296167373657,
          0.9996567964553833,
          0.9984925985336304,
          0.9993674159049988,
          0.9414125680923462,
          0.9991069436073303,
          0.9972112774848938,
          0.9979523420333862,
          0.9785904884338379,
          0.99888676404953,
          0.9993175268173218,
          0.997849702835083,
          0.9977547526359558,
          0.9993871450424194,
          0.9994187355041504,
          0.9965798258781433,
          0.9992799162864685,
          0.6959949135780334,
          0.9487632513046265,
          0.998963475227356,
          0.9981277585029602,
          0.9975436329841614,
          0.9938503503799438,
          0.9988082647323608,
          0.9994723200798035,
          0.9992901086807251,
          0.995139479637146,
          0.9988855719566345,
          0.9983826875686646,
          0.9997541308403015,
          0.9977357387542725,
          0.9719669222831726,
          0.9665957689285278,
          0.98972088098526,
          0.928842306137085,
          0.9952625036239624,
          0.9990641474723816,
          0.9997362494468689,
          0.9478803873062134,
          0.9917669892311096,
          0.9986617565155029,
          0.9206374287605286,
          0.9977219700813293,
          0.978880763053894,
          0.9722481966018677,
          0.9952319264411926,
          0.9959446787834167,
          0.9922339916229248,
          0.9744875431060791,
          0.9969019889831543,
          0.9918327331542969,
          0.9907845258712769,
          0.9994710087776184,
          0.9991382360458374,
          0.9996449947357178,
          0.9909862279891968,
          0.9952316880226135,
          0.9988299012184143,
          0.9987953901290894,
          0.9997656941413879,
          0.9891396164894104,
          0.9136707782745361,
          0.9855077862739563,
          0.9966884255409241,
          0.995214581489563,
          0.9996687173843384,
          0.9782376289367676,
          0.9995757937431335,
          0.9986391663551331,
          0.9975166320800781,
          0.9963028430938721,
          0.9991125464439392,
          0.9986170530319214,
          0.9980777502059937,
          0.9993158578872681,
          0.9994485974311829,
          0.9976235032081604,
          0.9497989416122437,
          0.7768644094467163,
          0.9974974989891052,
          0.9994142055511475,
          0.9998000264167786,
          0.9939849972724915,
          0.9952124357223511,
          0.9986849427223206,
          0.9946405291557312,
          0.9995693564414978,
          0.9996483325958252,
          0.9969934225082397,
          0.99920254945755,
          0.999359667301178,
          0.9997581839561462,
          0.9986869692802429,
          0.9967002272605896,
          0.9969456791877747,
          0.9700191020965576,
          0.9140102863311768,
          0.9966809153556824,
          0.9773908853530884,
          0.8681064248085022,
          0.9745678305625916,
          0.9991694688796997,
          0.9954730868339539,
          0.9963556528091431,
          0.9714420437812805,
          0.9953497052192688,
          0.9996139407157898,
          0.9939115047454834,
          0.9757086038589478,
          0.9910528063774109,
          0.9930170774459839,
          0.9536529779434204,
          0.9996500015258789,
          0.9997010827064514,
          0.9992544054985046,
          0.9903753399848938,
          0.9994031190872192,
          0.9988412261009216,
          0.9967988729476929,
          0.9987344145774841,
          0.9994617104530334,
          0.9993897676467896,
          0.9996289014816284,
          0.5852352976799011,
          0.9990742206573486,
          0.9121286273002625,
          0.9949895739555359,
          0.9780480861663818,
          0.9870883822441101,
          0.9968146681785583,
          0.9963733553886414,
          0.981338381767273,
          0.9995152950286865,
          0.9993042945861816,
          0.9946605563163757,
          0.9978138208389282,
          0.9737115502357483,
          0.8367202877998352,
          0.9968109726905823,
          0.9983114004135132,
          0.999670147895813,
          0.970512330532074,
          0.9972302317619324,
          0.9969257712364197,
          0.9955641031265259,
          0.3034838140010834,
          0.9972302317619324,
          0.9994557499885559,
          0.9863923192024231,
          0.9764427542686462,
          0.9545781016349792,
          0.9879476428031921,
          0.9976956248283386,
          0.998805046081543,
          0.9961286783218384,
          0.9949722290039062,
          0.8966857194900513,
          0.9987934827804565,
          0.9960522055625916,
          0.9994233846664429,
          0.9994077682495117,
          0.9997304081916809,
          0.9982617497444153,
          0.9984492063522339,
          0.9875027537345886,
          0.9651150107383728,
          0.9966409206390381,
          0.9988321661949158,
          0.9118269085884094,
          0.9942810535430908,
          0.9995480179786682,
          0.9996546506881714,
          0.9995328187942505,
          0.9705466032028198,
          0.9799185991287231,
          0.9795305132865906,
          0.9976935982704163,
          0.9997904896736145,
          0.9993267059326172,
          0.9983072280883789,
          0.9994459748268127,
          0.9995929598808289,
          0.9996929168701172,
          0.9993578791618347,
          0.9971080422401428,
          0.9995219707489014,
          0.9984772801399231,
          0.9992470741271973,
          0.9991297125816345,
          0.9987988471984863,
          0.9882504940032959,
          0.9992861151695251,
          0.9729952812194824,
          0.9972262978553772,
          0.9964427351951599,
          0.9991146922111511,
          0.9983648657798767,
          0.9992830157279968,
          0.9923352599143982,
          0.9994114637374878,
          0.9985047578811646,
          0.9960640072822571,
          0.9996200799942017,
          0.9978805780410767,
          0.9989331364631653,
          0.9986222982406616,
          0.9932796359062195,
          0.9662458300590515,
          0.9969320297241211,
          0.9436137080192566,
          0.9874059557914734,
          0.9917659163475037,
          0.9987014532089233,
          0.9995717406272888,
          0.9257838726043701,
          0.986382246017456,
          0.8887186050415039,
          0.9980247020721436,
          0.9961308240890503,
          0.9347580075263977,
          0.9978592991828918,
          0.9992697834968567,
          0.9992260932922363,
          0.8828156590461731,
          0.9887216091156006,
          0.9996011853218079,
          0.9991188645362854,
          0.9832021594047546,
          0.9986754059791565,
          0.9928913116455078,
          0.8511661887168884,
          0.9929478168487549,
          0.9966932535171509,
          0.9926795959472656,
          0.9964615702629089,
          0.9962899684906006,
          0.9948354959487915,
          0.9978941082954407,
          0.9991806149482727,
          0.9988933205604553,
          0.996123731136322,
          0.9859315156936646,
          0.9932924509048462,
          0.9979844093322754,
          0.9915743470191956,
          0.9833006858825684,
          0.9995095729827881,
          0.9995972514152527,
          0.9942305088043213,
          0.9968313574790955,
          0.3941640257835388,
          0.8996930718421936,
          0.9995437264442444,
          0.9985653758049011,
          0.9959243535995483,
          0.9983561635017395,
          0.94516521692276,
          0.9991903901100159,
          0.9995157718658447,
          0.9754957556724548,
          0.9940546154975891,
          0.9997530579566956,
          0.9987331032752991,
          0.999489426612854,
          0.992984414100647,
          0.9997175335884094,
          0.9993764758110046,
          0.9984018206596375,
          0.9917539358139038,
          0.9990091323852539,
          0.9984117746353149,
          0.9980389475822449,
          0.9859311580657959,
          0.999299168586731,
          0.994793713092804,
          0.9995467066764832,
          0.9996501207351685,
          0.9986973404884338,
          0.9893742203712463,
          0.988950788974762,
          0.9595420956611633,
          0.9972489476203918,
          0.9771271347999573,
          0.9957196116447449,
          0.9985377788543701,
          0.9981074333190918,
          0.9982276558876038,
          0.9985451698303223,
          0.9782690405845642,
          0.9973783493041992,
          0.9983606934547424,
          0.9776032567024231,
          0.9995991587638855,
          0.9896848201751709,
          0.9993211030960083,
          0.9957246780395508,
          0.9519957900047302,
          0.9996434450149536,
          0.992443859577179,
          0.9995638728141785,
          0.9996809959411621,
          0.9933542013168335,
          0.9994601607322693,
          0.9820131659507751,
          0.9956499934196472,
          0.998017430305481,
          0.9990493655204773,
          0.9350696206092834,
          0.9877821803092957,
          0.9996960163116455,
          0.999377965927124,
          0.9965768456459045,
          0.9537738561630249,
          0.9988676309585571,
          0.9737482070922852,
          0.9987125396728516,
          0.9992514252662659,
          0.9679664373397827,
          0.998754620552063,
          0.9980531930923462,
          0.9237149953842163,
          0.9952682852745056,
          0.9972315430641174,
          0.9990418553352356,
          0.9926060438156128,
          0.9977124929428101,
          0.9993224143981934,
          0.9937669038772583,
          0.9995427131652832,
          0.9931997656822205,
          0.8939399123191833,
          0.9213055968284607,
          0.9993719458580017,
          0.9963458180427551,
          0.7677649259567261,
          0.999061644077301,
          0.9872474670410156,
          0.9946969747543335,
          0.9996739625930786,
          0.9965744018554688,
          0.9992820620536804,
          0.9984204769134521,
          0.9980762004852295,
          0.9984036087989807,
          0.9631035923957825,
          0.9994736313819885,
          0.9987971782684326,
          0.9995205402374268,
          0.9901845455169678,
          0.9906546473503113,
          0.999794065952301,
          0.9990572333335876,
          0.9973117113113403,
          0.9985668063163757,
          0.9917640089988708,
          0.9991835951805115,
          0.9989633560180664,
          0.9968376159667969,
          0.9837195873260498,
          0.9943438768386841,
          0.9987649917602539,
          0.9087905287742615,
          0.9996315240859985,
          0.9997275471687317,
          0.9861693382263184,
          0.9973080158233643,
          0.9880490899085999,
          0.9924746155738831,
          0.9927331209182739,
          0.9972414970397949,
          0.9969474673271179,
          0.9991255402565002,
          0.9996150732040405,
          0.9911118149757385,
          0.9996435642242432,
          0.9762037992477417,
          0.9992164373397827,
          0.9996342658996582,
          0.9796185493469238,
          0.999504566192627,
          0.9996528625488281,
          0.9992978572845459,
          0.9953043460845947,
          0.9989306330680847,
          0.9930867552757263,
          0.9491447806358337,
          0.9992213249206543,
          0.9980576634407043,
          0.9996516704559326,
          0.9963223934173584,
          0.902497410774231,
          0.9968083500862122,
          0.9563865661621094,
          0.9961646795272827,
          0.9988712668418884,
          0.9996720552444458,
          0.9997623562812805,
          0.9261073470115662,
          0.9996200799942017,
          0.9989632368087769,
          0.9973134398460388,
          0.9995911717414856,
          0.9975401163101196,
          0.9857696294784546,
          0.9980701804161072,
          0.993057370185852,
          0.9982460737228394,
          0.9993839263916016,
          0.9963139891624451,
          0.999332845211029,
          0.9996328353881836,
          0.9994514584541321,
          0.9995524287223816,
          0.9975215792655945,
          0.9982549548149109,
          0.9989737272262573,
          0.9984362721443176,
          0.961187481880188,
          0.9996273517608643,
          0.9511721730232239,
          0.9931375980377197,
          0.9991052746772766,
          0.9986936450004578,
          0.8598424196243286,
          0.9511836767196655,
          0.9982085227966309,
          0.9784206748008728,
          0.9091335535049438,
          0.9980691075325012,
          0.9961940050125122,
          0.9997100234031677,
          0.9972339272499084,
          0.9969106316566467,
          0.996539831161499,
          0.8163403272628784,
          0.9952823519706726,
          0.9972357153892517,
          0.9952427744865417,
          0.9988662004470825,
          0.9997139573097229,
          0.999437153339386,
          0.987006425857544,
          0.9565572142601013,
          0.9965795874595642,
          0.9975616931915283,
          0.9961185455322266,
          0.9983654618263245,
          0.997032880783081,
          0.9995383024215698,
          0.9978083968162537,
          0.9986997842788696,
          0.955881655216217,
          0.9992921352386475,
          0.9908756017684937,
          0.9464421272277832,
          0.9979329109191895,
          0.9978792667388916,
          0.9994656443595886,
          0.9997707009315491,
          0.9993754029273987,
          0.8226382732391357,
          0.9353819489479065,
          0.9989981055259705,
          0.9926794767379761,
          0.9985911250114441,
          0.9922797679901123,
          0.9994319081306458,
          0.999208390712738,
          0.9969022870063782,
          0.9967093467712402,
          0.9995595812797546,
          0.9957569241523743,
          0.9986328482627869,
          0.9727349877357483,
          0.999242901802063,
          0.9851444959640503,
          0.9395793676376343,
          0.9979677796363831,
          0.8419524431228638,
          0.9997901320457458,
          0.9792766571044922,
          0.999237060546875,
          0.9526138305664062,
          0.9351909756660461,
          0.9995457530021667,
          0.7716862559318542,
          0.997028648853302,
          0.995705783367157,
          0.9806155562400818,
          0.8912330269813538,
          0.9989578723907471,
          0.9988137483596802,
          0.9994223117828369,
          0.9948392510414124,
          0.9973496198654175,
          0.9981191754341125,
          0.9975236058235168,
          0.9746626019477844,
          0.9987289309501648,
          0.9984815716743469,
          0.994461178779602,
          0.9930487871170044,
          0.9837972521781921,
          0.9955050349235535,
          0.9897253513336182,
          0.9981980919837952,
          0.9585191607475281,
          0.9954452514648438,
          0.982384204864502,
          0.995323121547699,
          0.9976534247398376,
          0.9984390139579773,
          0.9663374423980713,
          0.8108240962028503,
          0.9988670349121094,
          0.9974722266197205,
          0.9960833787918091,
          0.9981369972229004,
          0.9992799162864685,
          0.9750403165817261,
          0.9993890523910522,
          0.9988018274307251,
          0.9995318651199341,
          0.9994761347770691,
          0.4149438440799713,
          0.998150646686554,
          0.9989880919456482,
          0.9992367029190063,
          0.9866782426834106,
          0.9975207448005676,
          0.9982845187187195,
          0.9994984865188599,
          0.9937276840209961,
          0.9990190267562866,
          0.983590304851532,
          0.9991375207901001,
          0.9972856044769287,
          0.960337221622467,
          0.997852087020874,
          0.9986060261726379,
          0.9806078672409058,
          0.9996985197067261,
          0.9996871948242188,
          0.9947810769081116,
          0.9772933125495911,
          0.997850775718689,
          0.9991191029548645,
          0.9956501126289368,
          0.9997642636299133,
          0.9995459914207458,
          0.9996370077133179,
          0.996450662612915,
          0.9978297352790833,
          0.774621307849884,
          0.9881103038787842,
          0.9989292025566101,
          0.9990074038505554,
          0.996620774269104,
          0.998816728591919,
          0.9991532564163208,
          0.999487042427063,
          0.977777898311615,
          0.8613700270652771,
          0.9984827637672424,
          0.9994274377822876,
          0.9997463822364807,
          0.9874637126922607,
          0.9979298114776611,
          0.8769713640213013,
          0.999026894569397,
          0.9990707039833069,
          0.9994956254959106,
          0.9955155253410339,
          0.9961207509040833,
          0.9997972846031189,
          0.9790112376213074,
          0.9973631501197815,
          0.9987214207649231,
          0.9052582383155823,
          0.9970468878746033,
          0.9977001547813416,
          0.9995095729827881,
          0.995859682559967,
          0.9975495934486389,
          0.9832937717437744,
          0.9996768236160278,
          0.9985945820808411,
          0.8459019064903259,
          0.9991191029548645,
          0.9997112154960632,
          0.9992056488990784,
          0.9989566802978516,
          0.9998086094856262,
          0.9706839323043823,
          0.9796975255012512,
          0.9997454285621643,
          0.9993746876716614,
          0.9960982799530029,
          0.9979670643806458,
          0.9783798456192017,
          0.9992756247520447,
          0.9953871369361877,
          0.9952840209007263,
          0.9968151450157166,
          0.9983440637588501,
          0.9156602621078491,
          0.43740278482437134,
          0.9923388957977295,
          0.9988288283348083,
          0.9866365790367126,
          0.9976805448532104,
          0.9995312690734863,
          0.9920260310173035,
          0.9993245601654053,
          0.9983898401260376,
          0.9955551028251648,
          0.9927880167961121,
          0.9990915060043335,
          0.9990975856781006,
          0.9760341048240662,
          0.978783369064331,
          0.9994069337844849,
          0.999508261680603,
          0.9834161996841431,
          0.8672399520874023,
          0.9480399489402771,
          0.9992989301681519,
          0.9982494711875916,
          0.9995712637901306,
          0.9975599050521851,
          0.9977598190307617,
          0.9993284940719604,
          0.9990954399108887,
          0.9991576671600342,
          0.8201925754547119,
          0.9996297359466553,
          0.999243974685669,
          0.9963458180427551,
          0.9945620894432068,
          0.9974121451377869,
          0.9989500641822815,
          0.9982871413230896,
          0.9953542947769165,
          0.9990662932395935,
          0.9997416138648987,
          0.9992076754570007,
          0.9951388835906982,
          0.9988256096839905,
          0.9984071850776672,
          0.9884434342384338,
          0.9935082197189331,
          0.9996092915534973,
          0.9996685981750488,
          0.9838356971740723,
          0.9975226521492004,
          0.9964756369590759,
          0.9936850666999817,
          0.999265730381012,
          0.9967652559280396,
          0.995231568813324,
          0.9955853223800659,
          0.999344527721405,
          0.9155484437942505,
          0.9998168349266052,
          0.9988163709640503,
          0.9972207546234131,
          0.9915747046470642,
          0.9955369234085083,
          0.9777616262435913,
          0.9804744720458984,
          0.9994261264801025,
          0.8822184801101685,
          0.30882659554481506,
          0.9989326596260071,
          0.6801570057868958,
          0.9966867566108704,
          0.9988659620285034,
          0.9987757802009583,
          0.9997983574867249,
          0.985423743724823,
          0.9975469708442688,
          0.9979380965232849,
          0.9991031885147095,
          0.944898784160614,
          0.9998013377189636,
          0.9991280436515808,
          0.9954367280006409,
          0.9782087802886963,
          0.999468982219696,
          0.968785285949707,
          0.9978451728820801,
          0.9986135959625244,
          0.9904054999351501,
          0.9913492202758789,
          0.9820541143417358,
          0.9828656315803528,
          0.99901282787323,
          0.999683141708374,
          0.996383547782898,
          0.9996082186698914,
          0.997093915939331,
          0.9998224377632141,
          0.9952455163002014,
          0.9987142086029053,
          0.9913938641548157,
          0.9991996884346008,
          0.9993541836738586,
          0.9995920062065125,
          0.9983371496200562,
          0.997965931892395,
          0.999321699142456,
          0.9971436858177185,
          0.9993865489959717,
          0.9981416463851929,
          0.9991170763969421,
          0.999657154083252,
          0.9989981055259705,
          0.994122326374054,
          0.9991733431816101,
          0.9923245906829834,
          0.9889113903045654,
          0.9986037611961365,
          0.9973036050796509,
          0.98783278465271,
          0.9992254972457886,
          0.9994097948074341,
          0.9907470941543579,
          0.9994196891784668,
          0.9941149950027466,
          0.9993757605552673,
          0.9994297623634338,
          0.9965429902076721,
          0.9997462630271912,
          0.9973852038383484,
          0.9974042773246765,
          0.9977931976318359,
          0.9983949065208435,
          0.9981036186218262,
          0.9921644926071167,
          0.967252790927887,
          0.9967204928398132,
          0.9951149225234985,
          0.963681697845459,
          0.9994396567344666,
          0.9923056960105896,
          0.9987928867340088,
          0.9755987524986267,
          0.9982421398162842,
          0.9938410520553589,
          0.9980852603912354,
          0.996842622756958,
          0.9979070425033569,
          0.9644293189048767,
          0.9986478686332703,
          0.9550713896751404,
          0.9993287324905396,
          0.9834238290786743,
          0.9932383298873901,
          0.9996999502182007,
          0.9997039437294006,
          0.9985619187355042,
          0.998488187789917,
          0.9976580142974854,
          0.9990484118461609,
          0.9987995624542236,
          0.9985073208808899,
          0.9988818764686584,
          0.9982835054397583,
          0.9900588393211365,
          0.9813826680183411,
          0.9994149208068848,
          0.9847437739372253,
          0.9996277093887329,
          0.9981973767280579,
          0.9998094439506531,
          0.9976763129234314,
          0.9973022937774658,
          0.9882810711860657,
          0.9994667172431946,
          0.998026430606842,
          0.9184165000915527,
          0.9550022482872009,
          0.998146653175354,
          0.999230146408081,
          0.9496535658836365,
          0.9994491934776306,
          0.9997031092643738,
          0.9994787573814392,
          0.9987561702728271,
          0.9994811415672302,
          0.998748779296875,
          0.9715200066566467,
          0.987423300743103,
          0.9993602633476257,
          0.999250590801239,
          0.9955788254737854,
          0.9996091723442078,
          0.9970270991325378,
          0.9791391491889954,
          0.9504572153091431,
          0.9451597929000854,
          0.9992758631706238,
          0.9995276927947998,
          0.9433580636978149,
          0.9854274392127991,
          0.9269809126853943,
          0.9981582760810852,
          0.9960458874702454,
          0.9991446733474731,
          0.9973771572113037,
          0.9893830418586731,
          0.9995444416999817,
          0.997605562210083,
          0.981240451335907,
          0.9997580647468567,
          0.9971916079521179,
          0.9955282807350159,
          0.9977460503578186,
          0.9974400997161865,
          0.9973241090774536,
          0.9989811778068542,
          0.9960506558418274,
          0.9990664124488831,
          0.998997151851654,
          0.9995471835136414,
          0.9944121241569519,
          0.9996590614318848,
          0.9996743202209473,
          0.9923778772354126,
          0.8515896201133728,
          0.9977715611457825,
          0.9966509938240051,
          0.9987890124320984,
          0.9995711445808411,
          0.9823999404907227,
          0.9998087286949158,
          0.9967646598815918,
          0.9995973706245422,
          0.999268114566803,
          0.5942097306251526,
          0.9995854496955872,
          0.9956264495849609,
          0.9523923397064209,
          0.9996281862258911,
          0.9994619488716125,
          0.9665007591247559,
          0.9996590614318848,
          0.9997701048851013,
          0.9995560050010681,
          0.9957478642463684,
          0.9983747005462646,
          0.9971068501472473,
          0.9963346719741821,
          0.9972787499427795,
          0.9978717565536499,
          0.9994044303894043,
          0.9703731536865234,
          0.9986562728881836,
          0.9992600083351135,
          0.997016191482544,
          0.9298891425132751,
          0.9925627112388611,
          0.9912376403808594,
          0.9993970394134521,
          0.9994437098503113,
          0.9990666508674622,
          0.9807329177856445,
          0.9985266923904419,
          0.9921533465385437,
          0.9997758269309998,
          0.999663233757019,
          0.9786185026168823,
          0.9954240918159485,
          0.9963600039482117,
          0.997788667678833,
          0.9158415794372559,
          0.9976620674133301,
          0.9365326166152954,
          0.9968435764312744,
          0.922332763671875,
          0.9976673722267151,
          0.9993346333503723,
          0.9993365406990051,
          0.995741605758667,
          0.9958136677742004,
          0.9988977909088135,
          0.9960589408874512,
          0.997215747833252,
          0.9983283877372742,
          0.999041736125946,
          0.9980606436729431,
          0.9953778982162476,
          0.9787788987159729,
          0.9879838228225708,
          0.9994729161262512,
          0.9987112283706665,
          0.8634824752807617,
          0.91837078332901,
          0.9998114705085754,
          0.9956608414649963,
          0.9990069270133972,
          0.9938656687736511,
          0.9976662397384644,
          0.9977827668190002,
          0.9927939176559448,
          0.99925297498703,
          0.9995558857917786,
          0.9994465708732605,
          0.9948148131370544,
          0.996494710445404,
          0.9855867624282837,
          0.9943411350250244,
          0.9507781267166138,
          0.9997879862785339,
          0.9839370846748352,
          0.9990482926368713,
          0.9997408986091614,
          0.9997320771217346,
          0.9951788187026978,
          0.9982700347900391,
          0.9995672106742859,
          0.9978353381156921,
          0.999745786190033,
          0.9983277916908264,
          0.999618649482727,
          0.9728110432624817,
          0.9986090064048767,
          0.9978774785995483,
          0.9993664622306824,
          0.9691300988197327,
          0.9257591366767883,
          0.9976401329040527,
          0.9868017435073853,
          0.9983338713645935,
          0.9996387958526611,
          0.9996465444564819,
          0.9994359612464905,
          0.9953561425209045,
          0.9994841814041138,
          0.9947744011878967,
          0.995243489742279,
          0.9995357990264893,
          0.9997819066047668,
          0.9994630217552185,
          0.9967999458312988,
          0.9985779523849487,
          0.967983603477478,
          0.9993409514427185,
          0.9987249970436096,
          0.9977580904960632,
          0.997565746307373,
          0.9993767142295837,
          0.9772369861602783,
          0.9886229634284973,
          0.9970603585243225,
          0.9524670839309692,
          0.9994962215423584,
          0.9988190531730652,
          0.9825617074966431,
          0.9997515082359314,
          0.9986066222190857,
          0.9926006197929382,
          0.958433210849762,
          0.9991833567619324,
          0.9971490502357483,
          0.9986697435379028,
          0.9997552037239075,
          0.9992764592170715,
          0.9933492541313171,
          0.9990296363830566,
          0.9894870519638062,
          0.9916926622390747,
          0.9971535205841064,
          0.9975737929344177,
          0.989336371421814,
          0.9967378973960876,
          0.9998363256454468,
          0.9986432194709778,
          0.9995324611663818,
          0.9990562796592712,
          0.9990873336791992,
          0.9876511096954346,
          0.9994251728057861,
          0.9995710253715515,
          0.9353238344192505,
          0.9942966103553772,
          0.9993896484375,
          0.9923853874206543,
          0.99910968542099,
          0.9453510046005249,
          0.9954143762588501
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Probability assigned to the correct class"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Did it classify correctly?"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Probability to the correct class"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"1490e27c-e322-4a26-8bae-3b1f878c5818\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1490e27c-e322-4a26-8bae-3b1f878c5818\")) {                    Plotly.newPlot(                        \"1490e27c-e322-4a26-8bae-3b1f878c5818\",                        [{\"hovertemplate\":\"Did it classify correctly?=%{x}\\u003cbr\\u003eProbability to the correct class=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true],\"xaxis\":\"x\",\"y\":[0.9995113611221313,0.9975557327270508,0.9991400241851807,0.9995471835136414,0.9986056685447693,0.9874932765960693,0.9996241331100464,0.9978809952735901,0.9994816184043884,0.9996296167373657,0.9996567964553833,0.9984925985336304,0.9993674159049988,0.9414125680923462,0.9991069436073303,0.9972112774848938,0.9979523420333862,0.9785904884338379,0.99888676404953,0.9993175268173218,0.997849702835083,0.9977547526359558,0.9993871450424194,0.9994187355041504,0.9965798258781433,0.9992799162864685,0.6959949135780334,0.9487632513046265,0.998963475227356,0.9981277585029602,0.9975436329841614,0.9938503503799438,0.9988082647323608,0.9994723200798035,0.9992901086807251,0.995139479637146,0.9988855719566345,0.9983826875686646,0.9997541308403015,0.9977357387542725,0.9719669222831726,0.9665957689285278,0.98972088098526,0.928842306137085,0.9952625036239624,0.9990641474723816,0.9997362494468689,0.9478803873062134,0.9917669892311096,0.9986617565155029,0.9206374287605286,0.9977219700813293,0.978880763053894,0.9722481966018677,0.9952319264411926,0.9959446787834167,0.9922339916229248,0.9744875431060791,0.9969019889831543,0.9918327331542969,0.9907845258712769,0.9994710087776184,0.9991382360458374,0.9996449947357178,0.9909862279891968,0.9952316880226135,0.9988299012184143,0.9987953901290894,0.9997656941413879,0.9891396164894104,0.9136707782745361,0.9855077862739563,0.9966884255409241,0.995214581489563,0.9996687173843384,0.9782376289367676,0.9995757937431335,0.9986391663551331,0.9975166320800781,0.9963028430938721,0.9991125464439392,0.9986170530319214,0.9980777502059937,0.9993158578872681,0.9994485974311829,0.9976235032081604,0.9497989416122437,0.7768644094467163,0.9974974989891052,0.9994142055511475,0.9998000264167786,0.9939849972724915,0.9952124357223511,0.9986849427223206,0.9946405291557312,0.9995693564414978,0.9996483325958252,0.9969934225082397,0.99920254945755,0.999359667301178,0.9997581839561462,0.9986869692802429,0.9967002272605896,0.9969456791877747,0.9700191020965576,0.9140102863311768,0.9966809153556824,0.9773908853530884,0.8681064248085022,0.9745678305625916,0.9991694688796997,0.9954730868339539,0.9963556528091431,0.9714420437812805,0.9953497052192688,0.9996139407157898,0.9939115047454834,0.9757086038589478,0.9910528063774109,0.9930170774459839,0.9536529779434204,0.9996500015258789,0.9997010827064514,0.9992544054985046,0.9903753399848938,0.9994031190872192,0.9988412261009216,0.9967988729476929,0.9987344145774841,0.9994617104530334,0.9993897676467896,0.9996289014816284,0.5852352976799011,0.9990742206573486,0.9121286273002625,0.9949895739555359,0.9780480861663818,0.9870883822441101,0.9968146681785583,0.9963733553886414,0.981338381767273,0.9995152950286865,0.9993042945861816,0.9946605563163757,0.9978138208389282,0.9737115502357483,0.8367202877998352,0.9968109726905823,0.9983114004135132,0.999670147895813,0.970512330532074,0.9972302317619324,0.9969257712364197,0.9955641031265259,0.3034838140010834,0.9972302317619324,0.9994557499885559,0.9863923192024231,0.9764427542686462,0.9545781016349792,0.9879476428031921,0.9976956248283386,0.998805046081543,0.9961286783218384,0.9949722290039062,0.8966857194900513,0.9987934827804565,0.9960522055625916,0.9994233846664429,0.9994077682495117,0.9997304081916809,0.9982617497444153,0.9984492063522339,0.9875027537345886,0.9651150107383728,0.9966409206390381,0.9988321661949158,0.9118269085884094,0.9942810535430908,0.9995480179786682,0.9996546506881714,0.9995328187942505,0.9705466032028198,0.9799185991287231,0.9795305132865906,0.9976935982704163,0.9997904896736145,0.9993267059326172,0.9983072280883789,0.9994459748268127,0.9995929598808289,0.9996929168701172,0.9993578791618347,0.9971080422401428,0.9995219707489014,0.9984772801399231,0.9992470741271973,0.9991297125816345,0.9987988471984863,0.9882504940032959,0.9992861151695251,0.9729952812194824,0.9972262978553772,0.9964427351951599,0.9991146922111511,0.9983648657798767,0.9992830157279968,0.9923352599143982,0.9994114637374878,0.9985047578811646,0.9960640072822571,0.9996200799942017,0.9978805780410767,0.9989331364631653,0.9986222982406616,0.9932796359062195,0.9662458300590515,0.9969320297241211,0.9436137080192566,0.9874059557914734,0.9917659163475037,0.9987014532089233,0.9995717406272888,0.9257838726043701,0.986382246017456,0.8887186050415039,0.9980247020721436,0.9961308240890503,0.9347580075263977,0.9978592991828918,0.9992697834968567,0.9992260932922363,0.8828156590461731,0.9887216091156006,0.9996011853218079,0.9991188645362854,0.9832021594047546,0.9986754059791565,0.9928913116455078,0.8511661887168884,0.9929478168487549,0.9966932535171509,0.9926795959472656,0.9964615702629089,0.9962899684906006,0.9948354959487915,0.9978941082954407,0.9991806149482727,0.9988933205604553,0.996123731136322,0.9859315156936646,0.9932924509048462,0.9979844093322754,0.9915743470191956,0.9833006858825684,0.9995095729827881,0.9995972514152527,0.9942305088043213,0.9968313574790955,0.3941640257835388,0.8996930718421936,0.9995437264442444,0.9985653758049011,0.9959243535995483,0.9983561635017395,0.94516521692276,0.9991903901100159,0.9995157718658447,0.9754957556724548,0.9940546154975891,0.9997530579566956,0.9987331032752991,0.999489426612854,0.992984414100647,0.9997175335884094,0.9993764758110046,0.9984018206596375,0.9917539358139038,0.9990091323852539,0.9984117746353149,0.9980389475822449,0.9859311580657959,0.999299168586731,0.994793713092804,0.9995467066764832,0.9996501207351685,0.9986973404884338,0.9893742203712463,0.988950788974762,0.9595420956611633,0.9972489476203918,0.9771271347999573,0.9957196116447449,0.9985377788543701,0.9981074333190918,0.9982276558876038,0.9985451698303223,0.9782690405845642,0.9973783493041992,0.9983606934547424,0.9776032567024231,0.9995991587638855,0.9896848201751709,0.9993211030960083,0.9957246780395508,0.9519957900047302,0.9996434450149536,0.992443859577179,0.9995638728141785,0.9996809959411621,0.9933542013168335,0.9994601607322693,0.9820131659507751,0.9956499934196472,0.998017430305481,0.9990493655204773,0.9350696206092834,0.9877821803092957,0.9996960163116455,0.999377965927124,0.9965768456459045,0.9537738561630249,0.9988676309585571,0.9737482070922852,0.9987125396728516,0.9992514252662659,0.9679664373397827,0.998754620552063,0.9980531930923462,0.9237149953842163,0.9952682852745056,0.9972315430641174,0.9990418553352356,0.9926060438156128,0.9977124929428101,0.9993224143981934,0.9937669038772583,0.9995427131652832,0.9931997656822205,0.8939399123191833,0.9213055968284607,0.9993719458580017,0.9963458180427551,0.7677649259567261,0.999061644077301,0.9872474670410156,0.9946969747543335,0.9996739625930786,0.9965744018554688,0.9992820620536804,0.9984204769134521,0.9980762004852295,0.9984036087989807,0.9631035923957825,0.9994736313819885,0.9987971782684326,0.9995205402374268,0.9901845455169678,0.9906546473503113,0.999794065952301,0.9990572333335876,0.9973117113113403,0.9985668063163757,0.9917640089988708,0.9991835951805115,0.9989633560180664,0.9968376159667969,0.9837195873260498,0.9943438768386841,0.9987649917602539,0.9087905287742615,0.9996315240859985,0.9997275471687317,0.9861693382263184,0.9973080158233643,0.9880490899085999,0.9924746155738831,0.9927331209182739,0.9972414970397949,0.9969474673271179,0.9991255402565002,0.9996150732040405,0.9911118149757385,0.9996435642242432,0.9762037992477417,0.9992164373397827,0.9996342658996582,0.9796185493469238,0.999504566192627,0.9996528625488281,0.9992978572845459,0.9953043460845947,0.9989306330680847,0.9930867552757263,0.9491447806358337,0.9992213249206543,0.9980576634407043,0.9996516704559326,0.9963223934173584,0.902497410774231,0.9968083500862122,0.9563865661621094,0.9961646795272827,0.9988712668418884,0.9996720552444458,0.9997623562812805,0.9261073470115662,0.9996200799942017,0.9989632368087769,0.9973134398460388,0.9995911717414856,0.9975401163101196,0.9857696294784546,0.9980701804161072,0.993057370185852,0.9982460737228394,0.9993839263916016,0.9963139891624451,0.999332845211029,0.9996328353881836,0.9994514584541321,0.9995524287223816,0.9975215792655945,0.9982549548149109,0.9989737272262573,0.9984362721443176,0.961187481880188,0.9996273517608643,0.9511721730232239,0.9931375980377197,0.9991052746772766,0.9986936450004578,0.8598424196243286,0.9511836767196655,0.9982085227966309,0.9784206748008728,0.9091335535049438,0.9980691075325012,0.9961940050125122,0.9997100234031677,0.9972339272499084,0.9969106316566467,0.996539831161499,0.8163403272628784,0.9952823519706726,0.9972357153892517,0.9952427744865417,0.9988662004470825,0.9997139573097229,0.999437153339386,0.987006425857544,0.9565572142601013,0.9965795874595642,0.9975616931915283,0.9961185455322266,0.9983654618263245,0.997032880783081,0.9995383024215698,0.9978083968162537,0.9986997842788696,0.955881655216217,0.9992921352386475,0.9908756017684937,0.9464421272277832,0.9979329109191895,0.9978792667388916,0.9994656443595886,0.9997707009315491,0.9993754029273987,0.8226382732391357,0.9353819489479065,0.9989981055259705,0.9926794767379761,0.9985911250114441,0.9922797679901123,0.9994319081306458,0.999208390712738,0.9969022870063782,0.9967093467712402,0.9995595812797546,0.9957569241523743,0.9986328482627869,0.9727349877357483,0.999242901802063,0.9851444959640503,0.9395793676376343,0.9979677796363831,0.8419524431228638,0.9997901320457458,0.9792766571044922,0.999237060546875,0.9526138305664062,0.9351909756660461,0.9995457530021667,0.7716862559318542,0.997028648853302,0.995705783367157,0.9806155562400818,0.8912330269813538,0.9989578723907471,0.9988137483596802,0.9994223117828369,0.9948392510414124,0.9973496198654175,0.9981191754341125,0.9975236058235168,0.9746626019477844,0.9987289309501648,0.9984815716743469,0.994461178779602,0.9930487871170044,0.9837972521781921,0.9955050349235535,0.9897253513336182,0.9981980919837952,0.9585191607475281,0.9954452514648438,0.982384204864502,0.995323121547699,0.9976534247398376,0.9984390139579773,0.9663374423980713,0.8108240962028503,0.9988670349121094,0.9974722266197205,0.9960833787918091,0.9981369972229004,0.9992799162864685,0.9750403165817261,0.9993890523910522,0.9988018274307251,0.9995318651199341,0.9994761347770691,0.4149438440799713,0.998150646686554,0.9989880919456482,0.9992367029190063,0.9866782426834106,0.9975207448005676,0.9982845187187195,0.9994984865188599,0.9937276840209961,0.9990190267562866,0.983590304851532,0.9991375207901001,0.9972856044769287,0.960337221622467,0.997852087020874,0.9986060261726379,0.9806078672409058,0.9996985197067261,0.9996871948242188,0.9947810769081116,0.9772933125495911,0.997850775718689,0.9991191029548645,0.9956501126289368,0.9997642636299133,0.9995459914207458,0.9996370077133179,0.996450662612915,0.9978297352790833,0.774621307849884,0.9881103038787842,0.9989292025566101,0.9990074038505554,0.996620774269104,0.998816728591919,0.9991532564163208,0.999487042427063,0.977777898311615,0.8613700270652771,0.9984827637672424,0.9994274377822876,0.9997463822364807,0.9874637126922607,0.9979298114776611,0.8769713640213013,0.999026894569397,0.9990707039833069,0.9994956254959106,0.9955155253410339,0.9961207509040833,0.9997972846031189,0.9790112376213074,0.9973631501197815,0.9987214207649231,0.9052582383155823,0.9970468878746033,0.9977001547813416,0.9995095729827881,0.995859682559967,0.9975495934486389,0.9832937717437744,0.9996768236160278,0.9985945820808411,0.8459019064903259,0.9991191029548645,0.9997112154960632,0.9992056488990784,0.9989566802978516,0.9998086094856262,0.9706839323043823,0.9796975255012512,0.9997454285621643,0.9993746876716614,0.9960982799530029,0.9979670643806458,0.9783798456192017,0.9992756247520447,0.9953871369361877,0.9952840209007263,0.9968151450157166,0.9983440637588501,0.9156602621078491,0.43740278482437134,0.9923388957977295,0.9988288283348083,0.9866365790367126,0.9976805448532104,0.9995312690734863,0.9920260310173035,0.9993245601654053,0.9983898401260376,0.9955551028251648,0.9927880167961121,0.9990915060043335,0.9990975856781006,0.9760341048240662,0.978783369064331,0.9994069337844849,0.999508261680603,0.9834161996841431,0.8672399520874023,0.9480399489402771,0.9992989301681519,0.9982494711875916,0.9995712637901306,0.9975599050521851,0.9977598190307617,0.9993284940719604,0.9990954399108887,0.9991576671600342,0.8201925754547119,0.9996297359466553,0.999243974685669,0.9963458180427551,0.9945620894432068,0.9974121451377869,0.9989500641822815,0.9982871413230896,0.9953542947769165,0.9990662932395935,0.9997416138648987,0.9992076754570007,0.9951388835906982,0.9988256096839905,0.9984071850776672,0.9884434342384338,0.9935082197189331,0.9996092915534973,0.9996685981750488,0.9838356971740723,0.9975226521492004,0.9964756369590759,0.9936850666999817,0.999265730381012,0.9967652559280396,0.995231568813324,0.9955853223800659,0.999344527721405,0.9155484437942505,0.9998168349266052,0.9988163709640503,0.9972207546234131,0.9915747046470642,0.9955369234085083,0.9777616262435913,0.9804744720458984,0.9994261264801025,0.8822184801101685,0.30882659554481506,0.9989326596260071,0.6801570057868958,0.9966867566108704,0.9988659620285034,0.9987757802009583,0.9997983574867249,0.985423743724823,0.9975469708442688,0.9979380965232849,0.9991031885147095,0.944898784160614,0.9998013377189636,0.9991280436515808,0.9954367280006409,0.9782087802886963,0.999468982219696,0.968785285949707,0.9978451728820801,0.9986135959625244,0.9904054999351501,0.9913492202758789,0.9820541143417358,0.9828656315803528,0.99901282787323,0.999683141708374,0.996383547782898,0.9996082186698914,0.997093915939331,0.9998224377632141,0.9952455163002014,0.9987142086029053,0.9913938641548157,0.9991996884346008,0.9993541836738586,0.9995920062065125,0.9983371496200562,0.997965931892395,0.999321699142456,0.9971436858177185,0.9993865489959717,0.9981416463851929,0.9991170763969421,0.999657154083252,0.9989981055259705,0.994122326374054,0.9991733431816101,0.9923245906829834,0.9889113903045654,0.9986037611961365,0.9973036050796509,0.98783278465271,0.9992254972457886,0.9994097948074341,0.9907470941543579,0.9994196891784668,0.9941149950027466,0.9993757605552673,0.9994297623634338,0.9965429902076721,0.9997462630271912,0.9973852038383484,0.9974042773246765,0.9977931976318359,0.9983949065208435,0.9981036186218262,0.9921644926071167,0.967252790927887,0.9967204928398132,0.9951149225234985,0.963681697845459,0.9994396567344666,0.9923056960105896,0.9987928867340088,0.9755987524986267,0.9982421398162842,0.9938410520553589,0.9980852603912354,0.996842622756958,0.9979070425033569,0.9644293189048767,0.9986478686332703,0.9550713896751404,0.9993287324905396,0.9834238290786743,0.9932383298873901,0.9996999502182007,0.9997039437294006,0.9985619187355042,0.998488187789917,0.9976580142974854,0.9990484118461609,0.9987995624542236,0.9985073208808899,0.9988818764686584,0.9982835054397583,0.9900588393211365,0.9813826680183411,0.9994149208068848,0.9847437739372253,0.9996277093887329,0.9981973767280579,0.9998094439506531,0.9976763129234314,0.9973022937774658,0.9882810711860657,0.9994667172431946,0.998026430606842,0.9184165000915527,0.9550022482872009,0.998146653175354,0.999230146408081,0.9496535658836365,0.9994491934776306,0.9997031092643738,0.9994787573814392,0.9987561702728271,0.9994811415672302,0.998748779296875,0.9715200066566467,0.987423300743103,0.9993602633476257,0.999250590801239,0.9955788254737854,0.9996091723442078,0.9970270991325378,0.9791391491889954,0.9504572153091431,0.9451597929000854,0.9992758631706238,0.9995276927947998,0.9433580636978149,0.9854274392127991,0.9269809126853943,0.9981582760810852,0.9960458874702454,0.9991446733474731,0.9973771572113037,0.9893830418586731,0.9995444416999817,0.997605562210083,0.981240451335907,0.9997580647468567,0.9971916079521179,0.9955282807350159,0.9977460503578186,0.9974400997161865,0.9973241090774536,0.9989811778068542,0.9960506558418274,0.9990664124488831,0.998997151851654,0.9995471835136414,0.9944121241569519,0.9996590614318848,0.9996743202209473,0.9923778772354126,0.8515896201133728,0.9977715611457825,0.9966509938240051,0.9987890124320984,0.9995711445808411,0.9823999404907227,0.9998087286949158,0.9967646598815918,0.9995973706245422,0.999268114566803,0.5942097306251526,0.9995854496955872,0.9956264495849609,0.9523923397064209,0.9996281862258911,0.9994619488716125,0.9665007591247559,0.9996590614318848,0.9997701048851013,0.9995560050010681,0.9957478642463684,0.9983747005462646,0.9971068501472473,0.9963346719741821,0.9972787499427795,0.9978717565536499,0.9994044303894043,0.9703731536865234,0.9986562728881836,0.9992600083351135,0.997016191482544,0.9298891425132751,0.9925627112388611,0.9912376403808594,0.9993970394134521,0.9994437098503113,0.9990666508674622,0.9807329177856445,0.9985266923904419,0.9921533465385437,0.9997758269309998,0.999663233757019,0.9786185026168823,0.9954240918159485,0.9963600039482117,0.997788667678833,0.9158415794372559,0.9976620674133301,0.9365326166152954,0.9968435764312744,0.922332763671875,0.9976673722267151,0.9993346333503723,0.9993365406990051,0.995741605758667,0.9958136677742004,0.9988977909088135,0.9960589408874512,0.997215747833252,0.9983283877372742,0.999041736125946,0.9980606436729431,0.9953778982162476,0.9787788987159729,0.9879838228225708,0.9994729161262512,0.9987112283706665,0.8634824752807617,0.91837078332901,0.9998114705085754,0.9956608414649963,0.9990069270133972,0.9938656687736511,0.9976662397384644,0.9977827668190002,0.9927939176559448,0.99925297498703,0.9995558857917786,0.9994465708732605,0.9948148131370544,0.996494710445404,0.9855867624282837,0.9943411350250244,0.9507781267166138,0.9997879862785339,0.9839370846748352,0.9990482926368713,0.9997408986091614,0.9997320771217346,0.9951788187026978,0.9982700347900391,0.9995672106742859,0.9978353381156921,0.999745786190033,0.9983277916908264,0.999618649482727,0.9728110432624817,0.9986090064048767,0.9978774785995483,0.9993664622306824,0.9691300988197327,0.9257591366767883,0.9976401329040527,0.9868017435073853,0.9983338713645935,0.9996387958526611,0.9996465444564819,0.9994359612464905,0.9953561425209045,0.9994841814041138,0.9947744011878967,0.995243489742279,0.9995357990264893,0.9997819066047668,0.9994630217552185,0.9967999458312988,0.9985779523849487,0.967983603477478,0.9993409514427185,0.9987249970436096,0.9977580904960632,0.997565746307373,0.9993767142295837,0.9772369861602783,0.9886229634284973,0.9970603585243225,0.9524670839309692,0.9994962215423584,0.9988190531730652,0.9825617074966431,0.9997515082359314,0.9986066222190857,0.9926006197929382,0.958433210849762,0.9991833567619324,0.9971490502357483,0.9986697435379028,0.9997552037239075,0.9992764592170715,0.9933492541313171,0.9990296363830566,0.9894870519638062,0.9916926622390747,0.9971535205841064,0.9975737929344177,0.989336371421814,0.9967378973960876,0.9998363256454468,0.9986432194709778,0.9995324611663818,0.9990562796592712,0.9990873336791992,0.9876511096954346,0.9994251728057861,0.9995710253715515,0.9353238344192505,0.9942966103553772,0.9993896484375,0.9923853874206543,0.99910968542099,0.9453510046005249,0.9954143762588501],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Did it classify correctly?\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability to the correct class\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Probability assigned to the correct class\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1490e27c-e322-4a26-8bae-3b1f878c5818');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args.base_seed = 51\n",
    "test_dataset = SortedDatasetExtended(size=1000, **args.__dict__).to(\"cuda\")\n",
    "toks, target = test_dataset.toks, test_dataset.target\n",
    "# toks, target = test_dataset.pad_toks.to('cuda'), test_dataset.is_sorted(test_dataset.pad_toks).to('cuda')\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits = model(toks)\n",
    "    selected_logits = logits[*(toks == test_dataset.END).nonzero(as_tuple=True)]\n",
    "    predicted_ans = selected_logits.argmax(-1)\n",
    "    acc = predicted_ans == target.squeeze()\n",
    "    missed_toks = toks[~acc]\n",
    "    probs = selected_logits.softmax(dim=-1)\n",
    "    probs_correct_class = probs[torch.arange(probs.shape[0]), target.squeeze()]\n",
    "\n",
    "print('Misclasified toks', missed_toks)\n",
    "print('Misclasified toks target', target[~acc].squeeze().tolist())\n",
    "print('Misclasified toks predicted answer', predicted_ans[~acc].tolist())\n",
    "print('Misclasified toks probability on predicted answer', (100*probs[~acc, predicted_ans[~acc].squeeze()]).round())\n",
    "print('Accuracy', acc.float().mean().item())\n",
    "mpu.scatter(x=acc, y=probs_correct_class, title='Probability assigned to the correct class',\n",
    "            labels=dict(x='Did it classify correctly?', y='Probability to the correct class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_dataset2 \u001b[39m=\u001b[39m SortedDatasetExtended(size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m toks, target \u001b[39m=\u001b[39m test_dataset\u001b[39m.\u001b[39mtoks, test_dataset\u001b[39m.\u001b[39mtarget\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n",
      "File \u001b[0;32m~/Projects/toy_model_challenges/dataset.py:129\u001b[0m, in \u001b[0;36mSortedDatasetExtended.__init__\u001b[0;34m(self, size, d_vocab, seq_len, n_ctx, d_vocab_out, seed, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, size: \u001b[39mint\u001b[39m, d_vocab: \u001b[39mint\u001b[39m, seq_len: \u001b[39mint\u001b[39m, n_ctx: \u001b[39mint\u001b[39m, d_vocab_out: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, seed: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(size, d_vocab, seq_len, n_ctx, d_vocab_out, seed)\n\u001b[1;32m    131\u001b[0m     \u001b[39m# seq_len for this model is the minimum length of the non-PAD sequence of tokens\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39m# Within a single batch the padding will start at random from seq_len to n_ctx  \u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mseq_len \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m n_ctx, \u001b[39m\"\u001b[39m\u001b[39mn_ctx must be equal to 2*seq_len + 2\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Projects/toy_model_challenges/dataset.py:17\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, size, d_vocab, seq_len, n_ctx, d_vocab_out, seed)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, size: \u001b[39mint\u001b[39m, d_vocab: \u001b[39mint\u001b[39m, seq_len: \u001b[39mint\u001b[39m, n_ctx: \u001b[39mint\u001b[39m, d_vocab_out: \u001b[39mint\u001b[39m, seed: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m):\n\u001b[1;32m     16\u001b[0m     np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(seed)\n\u001b[0;32m---> 17\u001b[0m     torch\u001b[39m.\u001b[39;49mmanual_seed(seed)\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m size\n\u001b[1;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_vocab \u001b[39m=\u001b[39m d_vocab\n",
      "File \u001b[0;32m~/anaconda3/envs/arena/lib/python3.11/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmanual_seed_all(seed)\n\u001b[1;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/anaconda3/envs/arena/lib/python3.11/site-packages/torch/cuda/random.py:113\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    110\u001b[0m         default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    111\u001b[0m         default_generator\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 113\u001b[0m _lazy_call(cb, seed_all\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/arena/lib/python3.11/site-packages/torch/cuda/__init__.py:183\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_lazy_call\u001b[39m(\u001b[39mcallable\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 183\u001b[0m         \u001b[39mcallable\u001b[39;49m()\n\u001b[1;32m    184\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[39m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[39m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[39m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         \u001b[39mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/anaconda3/envs/arena/lib/python3.11/site-packages/torch/cuda/random.py:111\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[1;32m    110\u001b[0m     default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 111\u001b[0m     default_generator\u001b[39m.\u001b[39mmanual_seed(seed)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SortedDataset(size=1000, **args.__dict__).to(\"cuda\")\n",
    "test_dataset = SortedDatasetExtended(size=1000, **args.__dict__).to(\"cuda\")\n",
    "toks, target = test_dataset.toks, test_dataset.target\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits = model(toks)\n",
    "    selected_logits = logits[*(toks == test_dataset.END).nonzero(as_tuple=True)]\n",
    "    acc = selected_logits.argmax(-1) == target.squeeze()\n",
    "    missed_toks = toks[~acc]\n",
    "    probs = selected_logits.softmax(dim=-1)\n",
    "    probs_correct_class = probs[torch.arange(probs.shape[0]), target.squeeze()]\n",
    "\n",
    "print('Short context toks shape', toks.shape)\n",
    "print('Misclasified toks', missed_toks)\n",
    "print('Misclasified toks target', target[~acc])\n",
    "print('Agreement between datasets sorting criteria', (test_dataset.compute_target(missed_toks) == test_dataset2.is_sorted(missed_toks)).float().mean().item())\n",
    "print('Accuracy on short context dataset', acc.float().mean().item())\n",
    "mpu.scatter(x=acc, y=probs_correct_class, title='Probability assigned to the correct class',\n",
    "            labels=dict(x='Did it classify correctly?', y='Probability to the correct class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HookedTransformer' object has no attribute 'W_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m W_pos \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mW_pos\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m      2\u001b[0m mpu\u001b[39m.\u001b[39mline(W_pos\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/arena/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HookedTransformer' object has no attribute 'W_pos'"
     ]
    }
   ],
   "source": [
    "W_pos = model.W_pos.detach()\n",
    "mpu.line(W_pos.norm(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified toks tensor([[30,  3,  3,  4,  6,  6,  7,  8,  8, 29, 11, 14, 14, 14, 31, 32],\n",
      "        [30,  7,  7,  7,  8,  8,  9,  9,  9, 10, 10, 14, 12, 12, 12, 31],\n",
      "        [30, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  4, 28, 28, 31],\n",
      "        [30, 22, 22, 23, 23, 23, 23, 25, 25, 25, 26, 26,  8, 31, 32, 32],\n",
      "        [30,  2,  2,  2,  3,  3,  3,  3,  4,  4,  0,  5,  5,  5, 31, 32],\n",
      "        [30, 27, 27, 27, 27, 27, 27, 27, 27, 17, 28, 28, 28, 28, 28, 31],\n",
      "        [30,  7,  8,  9,  9,  9, 11, 16, 16,  2, 22, 22, 31, 32, 32, 32],\n",
      "        [30, 10, 10, 14, 15, 16, 16, 16, 16, 18,  7, 18, 31, 32, 32, 32],\n",
      "        [30, 10, 10, 10, 11, 12, 13, 13, 14, 14,  4, 16, 17, 17, 31, 32],\n",
      "        [30, 13, 14, 14, 16, 18, 19, 21, 21,  1, 24, 31, 32, 32, 32, 32],\n",
      "        [30,  7,  7,  9,  9, 10, 11, 11, 19, 18, 18, 19, 19, 21, 22, 31],\n",
      "        [30, 10, 10, 10, 11, 13, 14, 14, 14, 14,  3, 15, 16, 17, 17, 31],\n",
      "        [30,  7,  7,  8, 11, 11, 14, 13, 14, 14, 15, 15, 16, 17, 31, 32],\n",
      "        [30,  3,  4,  5,  5,  7,  7,  8,  9, 10, 11, 26, 12, 13, 15, 31],\n",
      "        [30, 13, 13, 14, 14, 14, 16, 17, 17, 22, 24, 24, 12, 31, 32, 32],\n",
      "        [30, 13, 13, 15, 16, 17, 17, 18, 19, 27, 22, 22, 31, 32, 32, 32],\n",
      "        [30, 10, 15, 17, 18, 21, 24, 26, 26, 26, 15, 31, 32, 32, 32, 32],\n",
      "        [30,  6,  6,  7,  8,  9, 10, 13, 18, 11, 28, 31, 32, 32, 32, 32],\n",
      "        [30,  3,  4,  5,  6,  9, 10, 13, 14, 15, 15, 27, 16, 17, 31, 32],\n",
      "        [30,  2,  3,  5,  6,  7,  9, 10, 11, 13, 16, 18, 19, 21, 10, 31],\n",
      "        [30,  5,  5,  5,  5,  5,  5,  5,  5,  5,  2, 31, 32, 32, 32, 32],\n",
      "        [30,  2,  2,  2,  4,  5,  6,  9, 10, 13,  9, 16, 17, 31, 32, 32],\n",
      "        [30, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,  2, 31, 32, 32],\n",
      "        [30, 24, 24, 25, 25, 25, 25, 26, 29, 27, 31, 32, 32, 32, 32, 32],\n",
      "        [30,  5,  6,  6,  6,  7,  7,  8,  9, 10, 10, 11, 26, 12, 12, 31],\n",
      "        [30,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 21,  0,  0, 31, 32],\n",
      "        [30, 16, 16, 16, 17, 17, 18, 18, 19, 20, 20, 20,  0, 21, 21, 31],\n",
      "        [30,  7,  7,  7,  7,  8,  8,  8,  8,  9, 29,  9,  9, 31, 32, 32],\n",
      "        [30, 20, 20, 20, 21, 21, 21, 22, 23, 24,  0, 31, 32, 32, 32, 32],\n",
      "        [30,  9,  9,  9, 10, 12, 12, 13, 14, 15, 10, 31, 32, 32, 32, 32],\n",
      "        [30, 19, 19, 19, 19, 20, 20, 21, 22, 22,  6, 25, 25, 25, 31, 32],\n",
      "        [30, 24, 24, 25, 25, 25, 26, 27, 27,  6, 28, 31, 32, 32, 32, 32],\n",
      "        [30, 11, 11, 14, 13, 14, 15, 18, 20, 20, 21, 22, 23, 24, 25, 31],\n",
      "        [30, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 14, 28, 31, 32, 32],\n",
      "        [30, 10, 12, 14, 15, 15, 15, 16, 21, 22, 19, 24, 24, 24, 27, 31],\n",
      "        [30, 26, 26, 26, 27, 27, 26, 27, 27, 27, 28, 28, 28, 31, 32, 32],\n",
      "        [30, 10, 13, 14, 14, 15, 17, 20, 21, 21, 18, 31, 32, 32, 32, 32],\n",
      "        [30,  6,  6,  7,  8,  8, 10, 12, 12, 26, 14, 14, 16, 18, 18, 31],\n",
      "        [30, 13, 15, 16, 16, 16, 17, 17, 17, 18, 20, 21,  4, 21, 31, 32],\n",
      "        [30, 12, 13, 13, 14, 17, 19, 20, 20, 21, 14, 23, 25, 31, 32, 32],\n",
      "        [30,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9, 10, 10, 10,  3, 31],\n",
      "        [30,  3,  5,  9, 11, 13, 13, 22, 22,  4, 31, 32, 32, 32, 32, 32],\n",
      "        [30, 17, 19, 21, 22, 23, 24, 24, 25, 16, 26, 31, 32, 32, 32, 32],\n",
      "        [30,  2,  3,  7,  7,  9, 10, 10, 13, 13,  3, 31, 32, 32, 32, 32],\n",
      "        [30,  3,  7, 13, 16, 18, 19, 19, 20, 21,  4, 24, 31, 32, 32, 32],\n",
      "        [30,  3,  6,  7,  7,  7,  8,  8,  8, 26, 10, 10, 31, 32, 32, 32],\n",
      "        [30,  3,  3,  3,  4,  4,  5,  7,  7, 24,  8,  8, 31, 32, 32, 32],\n",
      "        [30, 20, 20, 20, 20, 20, 21, 21, 21, 21,  5, 21, 21, 21, 31, 32]],\n",
      "       device='cuda:0')\n",
      "Misclassified toks target tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
      "       device='cuda:0')\n",
      "Misclassified toks probs tensor([0.2667, 0.4754, 0.4172, 0.3455, 0.3150, 0.3927, 0.4888, 0.3151, 0.3727,\n",
      "        0.3446, 0.2952, 0.2883, 0.0095, 0.3751, 0.2996, 0.4106, 0.4113, 0.4302,\n",
      "        0.4783, 0.1882, 0.2264, 0.3442, 0.3506, 0.3124, 0.4010, 0.3412, 0.2827,\n",
      "        0.2393, 0.4182, 0.3092, 0.3828, 0.3376, 0.0061, 0.4507, 0.2414, 0.0209,\n",
      "        0.3134, 0.2402, 0.3201, 0.4923, 0.1898, 0.4912, 0.3722, 0.3031, 0.4047,\n",
      "        0.4608, 0.4540, 0.3171], device='cuda:0')\n",
      "Accuracy tensor(0.9040, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Did it classify correctly?=%{x}<br>Probability to the correct class=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          false,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          true,
          true,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          false,
          false,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true,
          true
         ],
         "xaxis": "x",
         "y": [
          0.9878215193748474,
          0.2666962742805481,
          0.7247181534767151,
          0.9992411136627197,
          0.9992563128471375,
          0.992909848690033,
          0.9941483736038208,
          0.9995837807655334,
          0.9992809891700745,
          0.9996659755706787,
          0.9996663331985474,
          0.9996744394302368,
          0.999638557434082,
          0.47542011737823486,
          0.6301355361938477,
          0.8662574291229248,
          0.9996609687805176,
          0.9996906518936157,
          0.9996542930603027,
          0.6548271179199219,
          0.9995554089546204,
          0.41723009943962097,
          0.34545573592185974,
          0.9993293285369873,
          0.7961411476135254,
          0.31502413749694824,
          0.9948975443840027,
          0.39269548654556274,
          0.9996356964111328,
          0.9996381998062134,
          0.9938024282455444,
          0.993266224861145,
          0.5742208957672119,
          0.9992209672927856,
          0.9990992546081543,
          0.5217062830924988,
          0.999431312084198,
          0.993448793888092,
          0.9996669292449951,
          0.9995895028114319,
          0.999677300453186,
          0.9996222257614136,
          0.9996603727340698,
          0.9993676543235779,
          0.4887608289718628,
          0.6710516214370728,
          0.978417158126831,
          0.9988034963607788,
          0.9996790885925293,
          0.9996258020401001,
          0.9947429895401001,
          0.999677300453186,
          0.9996858835220337,
          0.9507111310958862,
          0.9996631145477295,
          0.9994020462036133,
          0.9987019300460815,
          0.9994563460350037,
          0.9993900060653687,
          0.9991617202758789,
          0.9944872260093689,
          0.9995952248573303,
          0.9996930360794067,
          0.9995625615119934,
          0.9973821043968201,
          0.9989916682243347,
          0.9995866417884827,
          0.9385178089141846,
          0.9996870756149292,
          0.9996702671051025,
          0.9953557252883911,
          0.9996751546859741,
          0.9952542781829834,
          0.3150721788406372,
          0.9996789693832397,
          0.9996398687362671,
          0.37267041206359863,
          0.9911342263221741,
          0.9996379613876343,
          0.7008444666862488,
          0.9995852112770081,
          0.9996869564056396,
          0.9990900754928589,
          0.9865787625312805,
          0.999538779258728,
          0.9996733665466309,
          0.9748430252075195,
          0.999256432056427,
          0.9994915723800659,
          0.8237482905387878,
          0.9818587899208069,
          0.3446172773838043,
          0.2952044606208801,
          0.2882530391216278,
          0.9990317821502686,
          0.7149597406387329,
          0.9996618032455444,
          0.9116388559341431,
          0.8362141847610474,
          0.9773486852645874,
          0.999491810798645,
          0.9995571970939636,
          0.9954859614372253,
          0.9996819496154785,
          0.9965242743492126,
          0.9996570348739624,
          0.009509263560175896,
          0.9818783402442932,
          0.9994105100631714,
          0.999670147895813,
          0.9993723034858704,
          0.999452531337738,
          0.9991773962974548,
          0.6521099209785461,
          0.9994798302650452,
          0.37514644861221313,
          0.9989413619041443,
          0.999675989151001,
          0.7589486241340637,
          0.9996613264083862,
          0.9994483590126038,
          0.998991072177887,
          0.6921408176422119,
          0.631908118724823,
          0.9994957447052002,
          0.9759345054626465,
          0.9666496515274048,
          0.29963672161102295,
          0.9991920590400696,
          0.9995765089988708,
          0.4105580747127533,
          0.994999885559082,
          0.8352829217910767,
          0.8877224922180176,
          0.9992434978485107,
          0.9996830224990845,
          0.9995144605636597,
          0.9958213567733765,
          0.5848761796951294,
          0.9996514320373535,
          0.9996699094772339,
          0.9996743202209473,
          0.9996429681777954,
          0.41130051016807556,
          0.6082634925842285,
          0.9996799230575562,
          0.999666690826416,
          0.99459308385849,
          0.9958908557891846,
          0.9872130751609802,
          0.9994358420372009,
          0.754677414894104,
          0.9996554851531982,
          0.9996649026870728,
          0.999180018901825,
          0.43018224835395813,
          0.9996665716171265,
          0.8647004961967468,
          0.9996678829193115,
          0.9996612071990967,
          0.47827816009521484,
          0.9996652603149414,
          0.9993422627449036,
          0.9995505213737488,
          0.9996668100357056,
          0.9995278120040894,
          0.9995297193527222,
          0.18821825087070465,
          0.9950981736183167,
          0.9996863603591919,
          0.8798981308937073,
          0.9996776580810547,
          0.9996724128723145,
          0.9996345043182373,
          0.2264219969511032,
          0.9996702671051025,
          0.9753767848014832,
          0.9992870688438416,
          0.948218584060669,
          0.9921433925628662,
          0.9996675252914429,
          0.9973288774490356,
          0.9996459484100342,
          0.9996809959411621,
          0.9993330836296082,
          0.34423696994781494,
          0.9953169822692871,
          0.9996607303619385,
          0.6516193151473999,
          0.9866531491279602,
          0.6339707970619202,
          0.9996856451034546,
          0.9855729937553406,
          0.9994507431983948,
          0.7422141432762146,
          0.9996260404586792,
          0.9996817111968994,
          0.9991113543510437,
          0.9996682405471802,
          0.9977918863296509,
          0.5262534618377686,
          0.9996281862258911,
          0.9996931552886963,
          0.3505876362323761,
          0.9491468071937561,
          0.9994839429855347,
          0.9887050986289978,
          0.9996678829193115,
          0.9995899796485901,
          0.5482069849967957,
          0.9993066787719727,
          0.9996498823165894,
          0.9995125532150269,
          0.9996638298034668,
          0.9990423321723938,
          0.999687910079956,
          0.9839133620262146,
          0.9847398400306702,
          0.31241974234580994,
          0.9996826648712158,
          0.999164342880249,
          0.9996895790100098,
          0.9934365749359131,
          0.9996591806411743,
          0.9992019534111023,
          0.9950190782546997,
          0.9995241165161133,
          0.9859236478805542,
          0.9996867179870605,
          0.40099698305130005,
          0.9996227025985718,
          0.565483033657074,
          0.9996626377105713,
          0.9996641874313354,
          0.3411720395088196,
          0.9993884563446045,
          0.9960105419158936,
          0.9757691025733948,
          0.9996569156646729,
          0.9903094172477722,
          0.9938597679138184,
          0.998245358467102,
          0.9996211528778076,
          0.9995898604393005,
          0.9996473789215088,
          0.9996554851531982,
          0.9996734857559204,
          0.9996786117553711,
          0.28274455666542053,
          0.999527096748352,
          0.9333212375640869,
          0.23932361602783203,
          0.9996781349182129,
          0.9996374845504761,
          0.9995218515396118,
          0.9996547698974609,
          0.6862765550613403,
          0.9911364316940308,
          0.999607264995575,
          0.41818657517433167,
          0.9996709823608398,
          0.9799561500549316,
          0.9183860421180725,
          0.9836553335189819,
          0.9995543360710144,
          0.9756303429603577,
          0.9996548891067505,
          0.3091687858104706,
          0.9996192455291748,
          0.9996565580368042,
          0.9677887558937073,
          0.6349565386772156,
          0.9996558427810669,
          0.9964022636413574,
          0.9976955056190491,
          0.6591840982437134,
          0.9604464173316956,
          0.9944825172424316,
          0.938957929611206,
          0.9992676377296448,
          0.9996669292449951,
          0.7415222525596619,
          0.9996459484100342,
          0.9866062998771667,
          0.9993733763694763,
          0.9993889331817627,
          0.9992325305938721,
          0.38282957673072815,
          0.6829559206962585,
          0.9996581077575684,
          0.9991389513015747,
          0.6361616253852844,
          0.9996790885925293,
          0.9991280436515808,
          0.9995762705802917,
          0.999622106552124,
          0.9993775486946106,
          0.5408303737640381,
          0.9996598958969116,
          0.999087929725647,
          0.6455925703048706,
          0.33755502104759216,
          0.9990148544311523,
          0.9938534498214722,
          0.9996315240859985,
          0.7975261211395264,
          0.5190646648406982,
          0.9992062449455261,
          0.9996685981750488,
          0.9995972514152527,
          0.006098076701164246,
          0.9989930987358093,
          0.9996135830879211,
          0.9996694326400757,
          0.9996674060821533,
          0.9996598958969116,
          0.9905487895011902,
          0.7649303078651428,
          0.594454288482666,
          0.9992867112159729,
          0.7686506509780884,
          0.4507160484790802,
          0.24137218296527863,
          0.9994532465934753,
          0.9950224161148071,
          0.7694383859634399,
          0.9920627474784851,
          0.9937340617179871,
          0.9996258020401001,
          0.9996472597122192,
          0.9996488094329834,
          0.9992073178291321,
          0.8015527725219727,
          0.9957838654518127,
          0.9896424412727356,
          0.999582827091217,
          0.999672532081604,
          0.7976933121681213,
          0.9994781613349915,
          0.6912604570388794,
          0.9994897842407227,
          0.9996699094772339,
          0.9996575117111206,
          0.6412805914878845,
          0.9938973784446716,
          0.9993159770965576,
          0.9996241331100464,
          0.9993066787719727,
          0.9996588230133057,
          0.9995554089546204,
          0.9996722936630249,
          0.9994602799415588,
          0.9996373653411865,
          0.9940863847732544,
          0.020892973989248276,
          0.5238314867019653,
          0.9995400905609131,
          0.6869316697120667,
          0.9996868371963501,
          0.3133832812309265,
          0.9990940093994141,
          0.9912142753601074,
          0.9995452761650085,
          0.9824851155281067,
          0.999524712562561,
          0.9994041919708252,
          0.999603807926178,
          0.9996764659881592,
          0.9996380805969238,
          0.2402123212814331,
          0.9719617366790771,
          0.9996227025985718,
          0.999669075012207,
          0.9996600151062012,
          0.9993791580200195,
          0.999647855758667,
          0.990203857421875,
          0.9991464614868164,
          0.9996479749679565,
          0.9996019005775452,
          0.9990466237068176,
          0.9920654892921448,
          0.9869422912597656,
          0.32011446356773376,
          0.9753379821777344,
          0.9989614486694336,
          0.9992064833641052,
          0.9996200799942017,
          0.9996805191040039,
          0.7637644410133362,
          0.9996817111968994,
          0.9992408752441406,
          0.5151498317718506,
          0.6729096174240112,
          0.9992944002151489,
          0.9996886253356934,
          0.744653582572937,
          0.9961450099945068,
          0.9893698692321777,
          0.9996505975723267,
          0.5646829009056091,
          0.9996844530105591,
          0.9994515776634216,
          0.9992741942405701,
          0.9993259906768799,
          0.49234554171562195,
          0.8693553805351257,
          0.9993361830711365,
          0.5250962376594543,
          0.9990140199661255,
          0.999363362789154,
          0.9993896484375,
          0.18978461623191833,
          0.9996808767318726,
          0.9993016719818115,
          0.9994024038314819,
          0.9996793270111084,
          0.4911953806877136,
          0.9992954730987549,
          0.5498493909835815,
          0.3722139000892639,
          0.999426007270813,
          0.9993357062339783,
          0.9994575381278992,
          0.30308693647384644,
          0.9996706247329712,
          0.9993361830711365,
          0.9995379447937012,
          0.9942212104797363,
          0.9993471503257751,
          0.9950180053710938,
          0.9953902959823608,
          0.9996017813682556,
          0.9995181560516357,
          0.9929620623588562,
          0.9996501207351685,
          0.9993101358413696,
          0.963367223739624,
          0.9991238713264465,
          0.9996707439422607,
          0.9991207718849182,
          0.9996601343154907,
          0.999677300453186,
          0.983111560344696,
          0.7046965956687927,
          0.9964753985404968,
          0.5930737853050232,
          0.9982699155807495,
          0.9792232513427734,
          0.999657392501831,
          0.9996737241744995,
          0.9545063972473145,
          0.9908707737922668,
          0.9996353387832642,
          0.9946487545967102,
          0.9993990659713745,
          0.40469813346862793,
          0.9995169639587402,
          0.7446375489234924,
          0.46084707975387573,
          0.999613344669342,
          0.9996829032897949,
          0.9728570580482483,
          0.9994651675224304,
          0.5389671325683594,
          0.6675155758857727,
          0.9864920973777771,
          0.9996695518493652,
          0.9782031774520874,
          0.9924347400665283,
          0.7527532577514648,
          0.981770932674408,
          0.9875032305717468,
          0.9996013045310974,
          0.9992985725402832,
          0.992234468460083,
          0.6148345470428467,
          0.9996603727340698,
          0.9911086559295654,
          0.9993115663528442,
          0.9994915723800659,
          0.4539972245693207,
          0.31711745262145996,
          0.8176144361495972,
          0.9991747736930847,
          0.9995691180229187,
          0.9992007613182068,
          0.948622465133667,
          0.735706090927124,
          0.5729461908340454,
          0.9597010612487793,
          0.9993512034416199,
          0.9278652667999268,
          0.9956525564193726,
          0.9652580618858337,
          0.9994242191314697,
          0.9922771453857422,
          0.9996688365936279,
          0.9993900060653687,
          0.9996346235275269
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Probability assigned to the correct class"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Did it classify correctly?"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Probability to the correct class"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5a8d9a5b-aff6-499f-a9e3-b8b994362b40\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5a8d9a5b-aff6-499f-a9e3-b8b994362b40\")) {                    Plotly.newPlot(                        \"5a8d9a5b-aff6-499f-a9e3-b8b994362b40\",                        [{\"hovertemplate\":\"Did it classify correctly?=%{x}\\u003cbr\\u003eProbability to the correct class=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[true,false,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,false,false,true,true,false,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,false,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,false,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,false,true,true,true,true,true,true,false,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,false,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,false,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,true,true,true,true,false,true,true,true,true,false,true,true,false,true,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,true,true,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,false,false,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true,true],\"xaxis\":\"x\",\"y\":[0.9878215193748474,0.2666962742805481,0.7247181534767151,0.9992411136627197,0.9992563128471375,0.992909848690033,0.9941483736038208,0.9995837807655334,0.9992809891700745,0.9996659755706787,0.9996663331985474,0.9996744394302368,0.999638557434082,0.47542011737823486,0.6301355361938477,0.8662574291229248,0.9996609687805176,0.9996906518936157,0.9996542930603027,0.6548271179199219,0.9995554089546204,0.41723009943962097,0.34545573592185974,0.9993293285369873,0.7961411476135254,0.31502413749694824,0.9948975443840027,0.39269548654556274,0.9996356964111328,0.9996381998062134,0.9938024282455444,0.993266224861145,0.5742208957672119,0.9992209672927856,0.9990992546081543,0.5217062830924988,0.999431312084198,0.993448793888092,0.9996669292449951,0.9995895028114319,0.999677300453186,0.9996222257614136,0.9996603727340698,0.9993676543235779,0.4887608289718628,0.6710516214370728,0.978417158126831,0.9988034963607788,0.9996790885925293,0.9996258020401001,0.9947429895401001,0.999677300453186,0.9996858835220337,0.9507111310958862,0.9996631145477295,0.9994020462036133,0.9987019300460815,0.9994563460350037,0.9993900060653687,0.9991617202758789,0.9944872260093689,0.9995952248573303,0.9996930360794067,0.9995625615119934,0.9973821043968201,0.9989916682243347,0.9995866417884827,0.9385178089141846,0.9996870756149292,0.9996702671051025,0.9953557252883911,0.9996751546859741,0.9952542781829834,0.3150721788406372,0.9996789693832397,0.9996398687362671,0.37267041206359863,0.9911342263221741,0.9996379613876343,0.7008444666862488,0.9995852112770081,0.9996869564056396,0.9990900754928589,0.9865787625312805,0.999538779258728,0.9996733665466309,0.9748430252075195,0.999256432056427,0.9994915723800659,0.8237482905387878,0.9818587899208069,0.3446172773838043,0.2952044606208801,0.2882530391216278,0.9990317821502686,0.7149597406387329,0.9996618032455444,0.9116388559341431,0.8362141847610474,0.9773486852645874,0.999491810798645,0.9995571970939636,0.9954859614372253,0.9996819496154785,0.9965242743492126,0.9996570348739624,0.009509263560175896,0.9818783402442932,0.9994105100631714,0.999670147895813,0.9993723034858704,0.999452531337738,0.9991773962974548,0.6521099209785461,0.9994798302650452,0.37514644861221313,0.9989413619041443,0.999675989151001,0.7589486241340637,0.9996613264083862,0.9994483590126038,0.998991072177887,0.6921408176422119,0.631908118724823,0.9994957447052002,0.9759345054626465,0.9666496515274048,0.29963672161102295,0.9991920590400696,0.9995765089988708,0.4105580747127533,0.994999885559082,0.8352829217910767,0.8877224922180176,0.9992434978485107,0.9996830224990845,0.9995144605636597,0.9958213567733765,0.5848761796951294,0.9996514320373535,0.9996699094772339,0.9996743202209473,0.9996429681777954,0.41130051016807556,0.6082634925842285,0.9996799230575562,0.999666690826416,0.99459308385849,0.9958908557891846,0.9872130751609802,0.9994358420372009,0.754677414894104,0.9996554851531982,0.9996649026870728,0.999180018901825,0.43018224835395813,0.9996665716171265,0.8647004961967468,0.9996678829193115,0.9996612071990967,0.47827816009521484,0.9996652603149414,0.9993422627449036,0.9995505213737488,0.9996668100357056,0.9995278120040894,0.9995297193527222,0.18821825087070465,0.9950981736183167,0.9996863603591919,0.8798981308937073,0.9996776580810547,0.9996724128723145,0.9996345043182373,0.2264219969511032,0.9996702671051025,0.9753767848014832,0.9992870688438416,0.948218584060669,0.9921433925628662,0.9996675252914429,0.9973288774490356,0.9996459484100342,0.9996809959411621,0.9993330836296082,0.34423696994781494,0.9953169822692871,0.9996607303619385,0.6516193151473999,0.9866531491279602,0.6339707970619202,0.9996856451034546,0.9855729937553406,0.9994507431983948,0.7422141432762146,0.9996260404586792,0.9996817111968994,0.9991113543510437,0.9996682405471802,0.9977918863296509,0.5262534618377686,0.9996281862258911,0.9996931552886963,0.3505876362323761,0.9491468071937561,0.9994839429855347,0.9887050986289978,0.9996678829193115,0.9995899796485901,0.5482069849967957,0.9993066787719727,0.9996498823165894,0.9995125532150269,0.9996638298034668,0.9990423321723938,0.999687910079956,0.9839133620262146,0.9847398400306702,0.31241974234580994,0.9996826648712158,0.999164342880249,0.9996895790100098,0.9934365749359131,0.9996591806411743,0.9992019534111023,0.9950190782546997,0.9995241165161133,0.9859236478805542,0.9996867179870605,0.40099698305130005,0.9996227025985718,0.565483033657074,0.9996626377105713,0.9996641874313354,0.3411720395088196,0.9993884563446045,0.9960105419158936,0.9757691025733948,0.9996569156646729,0.9903094172477722,0.9938597679138184,0.998245358467102,0.9996211528778076,0.9995898604393005,0.9996473789215088,0.9996554851531982,0.9996734857559204,0.9996786117553711,0.28274455666542053,0.999527096748352,0.9333212375640869,0.23932361602783203,0.9996781349182129,0.9996374845504761,0.9995218515396118,0.9996547698974609,0.6862765550613403,0.9911364316940308,0.999607264995575,0.41818657517433167,0.9996709823608398,0.9799561500549316,0.9183860421180725,0.9836553335189819,0.9995543360710144,0.9756303429603577,0.9996548891067505,0.3091687858104706,0.9996192455291748,0.9996565580368042,0.9677887558937073,0.6349565386772156,0.9996558427810669,0.9964022636413574,0.9976955056190491,0.6591840982437134,0.9604464173316956,0.9944825172424316,0.938957929611206,0.9992676377296448,0.9996669292449951,0.7415222525596619,0.9996459484100342,0.9866062998771667,0.9993733763694763,0.9993889331817627,0.9992325305938721,0.38282957673072815,0.6829559206962585,0.9996581077575684,0.9991389513015747,0.6361616253852844,0.9996790885925293,0.9991280436515808,0.9995762705802917,0.999622106552124,0.9993775486946106,0.5408303737640381,0.9996598958969116,0.999087929725647,0.6455925703048706,0.33755502104759216,0.9990148544311523,0.9938534498214722,0.9996315240859985,0.7975261211395264,0.5190646648406982,0.9992062449455261,0.9996685981750488,0.9995972514152527,0.006098076701164246,0.9989930987358093,0.9996135830879211,0.9996694326400757,0.9996674060821533,0.9996598958969116,0.9905487895011902,0.7649303078651428,0.594454288482666,0.9992867112159729,0.7686506509780884,0.4507160484790802,0.24137218296527863,0.9994532465934753,0.9950224161148071,0.7694383859634399,0.9920627474784851,0.9937340617179871,0.9996258020401001,0.9996472597122192,0.9996488094329834,0.9992073178291321,0.8015527725219727,0.9957838654518127,0.9896424412727356,0.999582827091217,0.999672532081604,0.7976933121681213,0.9994781613349915,0.6912604570388794,0.9994897842407227,0.9996699094772339,0.9996575117111206,0.6412805914878845,0.9938973784446716,0.9993159770965576,0.9996241331100464,0.9993066787719727,0.9996588230133057,0.9995554089546204,0.9996722936630249,0.9994602799415588,0.9996373653411865,0.9940863847732544,0.020892973989248276,0.5238314867019653,0.9995400905609131,0.6869316697120667,0.9996868371963501,0.3133832812309265,0.9990940093994141,0.9912142753601074,0.9995452761650085,0.9824851155281067,0.999524712562561,0.9994041919708252,0.999603807926178,0.9996764659881592,0.9996380805969238,0.2402123212814331,0.9719617366790771,0.9996227025985718,0.999669075012207,0.9996600151062012,0.9993791580200195,0.999647855758667,0.990203857421875,0.9991464614868164,0.9996479749679565,0.9996019005775452,0.9990466237068176,0.9920654892921448,0.9869422912597656,0.32011446356773376,0.9753379821777344,0.9989614486694336,0.9992064833641052,0.9996200799942017,0.9996805191040039,0.7637644410133362,0.9996817111968994,0.9992408752441406,0.5151498317718506,0.6729096174240112,0.9992944002151489,0.9996886253356934,0.744653582572937,0.9961450099945068,0.9893698692321777,0.9996505975723267,0.5646829009056091,0.9996844530105591,0.9994515776634216,0.9992741942405701,0.9993259906768799,0.49234554171562195,0.8693553805351257,0.9993361830711365,0.5250962376594543,0.9990140199661255,0.999363362789154,0.9993896484375,0.18978461623191833,0.9996808767318726,0.9993016719818115,0.9994024038314819,0.9996793270111084,0.4911953806877136,0.9992954730987549,0.5498493909835815,0.3722139000892639,0.999426007270813,0.9993357062339783,0.9994575381278992,0.30308693647384644,0.9996706247329712,0.9993361830711365,0.9995379447937012,0.9942212104797363,0.9993471503257751,0.9950180053710938,0.9953902959823608,0.9996017813682556,0.9995181560516357,0.9929620623588562,0.9996501207351685,0.9993101358413696,0.963367223739624,0.9991238713264465,0.9996707439422607,0.9991207718849182,0.9996601343154907,0.999677300453186,0.983111560344696,0.7046965956687927,0.9964753985404968,0.5930737853050232,0.9982699155807495,0.9792232513427734,0.999657392501831,0.9996737241744995,0.9545063972473145,0.9908707737922668,0.9996353387832642,0.9946487545967102,0.9993990659713745,0.40469813346862793,0.9995169639587402,0.7446375489234924,0.46084707975387573,0.999613344669342,0.9996829032897949,0.9728570580482483,0.9994651675224304,0.5389671325683594,0.6675155758857727,0.9864920973777771,0.9996695518493652,0.9782031774520874,0.9924347400665283,0.7527532577514648,0.981770932674408,0.9875032305717468,0.9996013045310974,0.9992985725402832,0.992234468460083,0.6148345470428467,0.9996603727340698,0.9911086559295654,0.9993115663528442,0.9994915723800659,0.4539972245693207,0.31711745262145996,0.8176144361495972,0.9991747736930847,0.9995691180229187,0.9992007613182068,0.948622465133667,0.735706090927124,0.5729461908340454,0.9597010612487793,0.9993512034416199,0.9278652667999268,0.9956525564193726,0.9652580618858337,0.9994242191314697,0.9922771453857422,0.9996688365936279,0.9993900060653687,0.9996346235275269],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Did it classify correctly?\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability to the correct class\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Probability assigned to the correct class\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5a8d9a5b-aff6-499f-a9e3-b8b994362b40');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_dataset2 = SortedDatasetExtended(size=5000, d_vocab=33, seq_len=8, n_ctx=16, seed=5).to(\"cuda\")\n",
    "# toks, target = test_dataset2.toks, test_dataset2.target\n",
    "test_dataset2 = SortedDatasetExtended(size=None, d_vocab=33, seq_len=8, n_ctx=16, seed=1)\n",
    "toks = test_dataset2.gen_almost_sorted_toks(500)\n",
    "target = test_dataset2.compute_target(toks).to(\"cuda\")\n",
    "toks = toks.to(\"cuda\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits = model(toks).detach()\n",
    "    selected_logits = logits[*(toks == test_dataset2.END).nonzero(as_tuple=True)]\n",
    "    acc = selected_logits.argmax(dim=-1) == target.squeeze()\n",
    "    missed_toks = toks[~acc]\n",
    "    probs = selected_logits.softmax(dim=-1)\n",
    "    probs_correct_class = probs[torch.arange(probs.shape[0]), target.squeeze()]\n",
    "\n",
    "print('Misclassified toks', missed_toks)\n",
    "print('Misclassified toks target', target[~acc])\n",
    "print('Misclassified toks probs', probs_correct_class[~acc])\n",
    "print('Accuracy', acc.float().mean())\n",
    "mpu.scatter(x=acc, y=probs_correct_class, title='Probability assigned to the correct class',\n",
    "            labels=dict(x='Did it classify correctly?', y='Probability to the correct class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/sorting_classifier_acc956.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00, Train loss = 0.1171, Accuracy: 0.960: : 196it [00:04, 40.29it/s]      \n",
      "Epoch 01, Train loss = 0.0766, Accuracy: 0.978: : 196it [00:05, 38.90it/s]\n",
      "Epoch 02, Train loss = 0.0787, Accuracy: 0.992: : 196it [00:04, 42.18it/s]      \n",
      "Epoch 03, Train loss = 0.0555, Accuracy: 0.994: : 196it [00:04, 39.56it/s]\n",
      "Epoch 04, Train loss = 0.0058, Accuracy: 0.996: : 196it [00:04, 40.66it/s]      \n",
      "Epoch 05, Train loss = 0.0037, Accuracy: 0.994: : 196it [00:04, 40.19it/s]\n",
      "Epoch 06, Train loss = 0.0064, Accuracy: 0.998: : 196it [00:04, 40.36it/s]      \n",
      "Epoch 07, Train loss = 0.0024, Accuracy: 0.994: : 196it [00:04, 39.87it/s]\n",
      "Epoch 08, Train loss = 0.0268, Accuracy: 0.990: : 196it [00:04, 41.99it/s]      \n",
      "Epoch 09, Train loss = 0.0034, Accuracy: 0.998: : 196it [00:05, 38.91it/s]\n"
     ]
    }
   ],
   "source": [
    "args = TrainArgs(\n",
    "    dataset=ContainedStringDataset,\n",
    "    d_vocab=33,\n",
    "    d_vocab_out=2,\n",
    "    n_ctx=18,\n",
    "    n_layers=2,\n",
    "    relevant_pos=[-1],\n",
    "    trainset_size=100_000,\n",
    "    valset_size=500,\n",
    "    epochs=10,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    base_seed=42,\n",
    "    d_model=64,\n",
    "    d_head=32,\n",
    "    n_heads=2,\n",
    "    d_mlp=None,\n",
    "    normalization_type=\"LN\",\n",
    "    use_wandb=False,\n",
    "    device=device,\n",
    ")\n",
    "model = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/contain_string_acc998.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00, Train loss = 0.1415, Accuracy: 0.938: : 196it [00:09, 21.07it/s]      \n",
      "Epoch 01, Train loss = 0.1116, Accuracy: 0.966: : 196it [00:08, 22.93it/s]\n",
      "Epoch 02, Train loss = 0.0983, Accuracy: 0.968: : 196it [00:08, 23.08it/s]      \n",
      "Epoch 03, Train loss = 0.0449, Accuracy: 0.972: : 196it [00:08, 22.59it/s]\n",
      "Epoch 04, Train loss = 0.0517, Accuracy: 0.972: : 196it [00:08, 22.96it/s]      \n",
      "Epoch 05, Train loss = 0.0706, Accuracy: 0.970: : 196it [00:08, 22.75it/s]\n",
      "Epoch 06, Train loss = 0.0750, Accuracy: 0.970: : 196it [00:08, 23.47it/s]      \n",
      "Epoch 07, Train loss = 0.1089, Accuracy: 0.978: : 196it [00:08, 22.24it/s]\n",
      "Epoch 08, Train loss = 0.0578, Accuracy: 0.980: : 196it [00:08, 22.81it/s]      \n",
      "Epoch 09, Train loss = 0.0212, Accuracy: 0.984: : 196it [00:08, 22.68it/s]\n",
      "Epoch 10, Train loss = 0.0513, Accuracy: 0.976: : 196it [00:08, 23.16it/s]      \n",
      "Epoch 11, Train loss = 0.0464, Accuracy: 0.984: : 196it [00:08, 22.21it/s]\n",
      "Epoch 12, Train loss = 0.0627, Accuracy: 0.970: : 196it [00:08, 22.79it/s]      \n",
      "Epoch 13, Train loss = 0.0181, Accuracy: 0.978: : 196it [00:08, 21.96it/s]\n",
      "Epoch 14, Train loss = 0.0511, Accuracy: 0.982: : 196it [00:08, 22.87it/s]      \n"
     ]
    }
   ],
   "source": [
    "args = TrainArgs(\n",
    "    dataset=AddUpToTargetDataset,\n",
    "    d_vocab=32,\n",
    "    d_vocab_out=2,\n",
    "    n_ctx=23,\n",
    "    n_layers=3,\n",
    "    relevant_pos=[-1],\n",
    "    trainset_size=100_000,\n",
    "    valset_size=500,\n",
    "    epochs=15,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.01, # Ups, I didn't notice I changed this\n",
    "    base_seed=42,\n",
    "    d_model=64,\n",
    "    d_head=32,\n",
    "    n_heads=2,\n",
    "    d_mlp=4*64,\n",
    "    normalization_type=\"LN\",\n",
    "    use_wandb=False,\n",
    "    device=device,\n",
    ")\n",
    "model = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'models/add_to_target_acc982.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00, Train loss = 1.9138, Accuracy: 0.264: : 196it [00:10, 18.46it/s]      \n",
      "Epoch 01, Train loss = 2.0150, Accuracy: 0.264: : 196it [00:09, 20.66it/s]\n",
      "Epoch 02, Train loss = 1.9721, Accuracy: 0.276: : 196it [00:09, 20.56it/s]      \n",
      "Epoch 03, Train loss = 1.7951, Accuracy: 0.246: : 196it [00:09, 21.13it/s]\n",
      "Epoch 04, Train loss = 1.7986, Accuracy: 0.260: : 196it [00:09, 21.41it/s]      \n",
      "Epoch 05, Train loss = 1.7997, Accuracy: 0.286: : 196it [00:09, 21.13it/s]\n",
      "Epoch 06, Train loss = 1.6757, Accuracy: 0.294: : 196it [00:09, 21.76it/s]      \n",
      "Epoch 07, Train loss = 1.7154, Accuracy: 0.316: : 196it [00:09, 20.77it/s]\n",
      "Epoch 08, Train loss = 1.6883, Accuracy: 0.304: : 196it [00:09, 21.67it/s]      \n",
      "Epoch 09, Train loss = 1.7542, Accuracy: 0.306: : 196it [00:09, 20.74it/s]\n",
      "Epoch 10, Train loss = 1.7831, Accuracy: 0.298: : 196it [00:09, 21.45it/s]      \n",
      "Epoch 11, Train loss = 1.7181, Accuracy: 0.280: : 196it [00:09, 20.58it/s]\n",
      "Epoch 12, Train loss = 1.7384, Accuracy: 0.288: : 196it [00:09, 20.60it/s]      \n",
      "Epoch 13, Train loss = 1.7442, Accuracy: 0.328: : 196it [00:09, 20.41it/s]\n",
      "Epoch 14, Train loss = 1.7268, Accuracy: 0.296: : 196it [00:09, 20.49it/s]      \n"
     ]
    }
   ],
   "source": [
    "args = TrainArgs(\n",
    "    dataset=AddUpToTargetValueDataset,\n",
    "    d_vocab=32,\n",
    "    d_vocab_out=30,\n",
    "    n_ctx=23,\n",
    "    n_layers=3,\n",
    "    relevant_pos=[-1],\n",
    "    trainset_size=100_000,\n",
    "    valset_size=500,\n",
    "    epochs=15,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    base_seed=42,\n",
    "    d_model=64,\n",
    "    d_head=32,\n",
    "    n_heads=2,\n",
    "    d_mlp=4*64,\n",
    "    normalization_type=\"LN\",\n",
    "    use_wandb=False,\n",
    "    device=device,\n",
    ")\n",
    "model = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/add_to_value_acc982.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
